{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6377d362e8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.47019608  0.15019608  0.30705882]\n",
      "   [ 0.34156863  0.31019608  0.75882353]\n",
      "   [ 0.69921569  0.50784314  0.79647059]\n",
      "   ..., \n",
      "   [ 0.32588235  0.43254902  0.61137255]\n",
      "   [ 0.67411765  0.7745098   0.2254902 ]\n",
      "   [ 0.36980392  0.11254902  0.22235294]]\n",
      "\n",
      "  [[ 0.11568627  0.56431373  0.52980392]\n",
      "   [ 0.50156863  0.77764706  0.32901961]\n",
      "   [ 0.44196078  0.69607843  0.81529412]\n",
      "   ..., \n",
      "   [ 0.70862745  0.42313725  0.3227451 ]\n",
      "   [ 0.39490196  0.1972549   0.84980392]\n",
      "   [ 0.66784314  0.74941176  0.85294118]]\n",
      "\n",
      "  [[ 0.25058824  0.71803922  0.81843137]\n",
      "   [ 0.67411765  0.39803922  0.39176471]\n",
      "   [ 0.10941176  0.26941176  0.4545098 ]\n",
      "   ..., \n",
      "   [ 0.72745098  0.1972549   0.25686275]\n",
      "   [ 0.16901961  0.3854902   0.72745098]\n",
      "   [ 0.29137255  0.89372549  0.53294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.69294118  0.55803922  0.8372549 ]\n",
      "   [ 0.85607843  0.15960784  0.56117647]\n",
      "   [ 0.60823529  0.18470588  0.44823529]\n",
      "   ..., \n",
      "   [ 0.47647059  0.73058824  0.58627451]\n",
      "   [ 0.32588235  0.74313725  0.38235294]\n",
      "   [ 0.61137255  0.4827451   0.10941176]]\n",
      "\n",
      "  [[ 0.41058824  0.80901961  0.17215686]\n",
      "   [ 0.83098039  0.79333333  0.59882353]\n",
      "   [ 0.43254902  0.1627451   0.38862745]\n",
      "   ..., \n",
      "   [ 0.16901961  0.40431373  0.44823529]\n",
      "   [ 0.63333333  0.39176471  0.52666667]\n",
      "   [ 0.34156863  0.57058824  0.31960784]]\n",
      "\n",
      "  [[ 0.48901961  0.55803922  0.23176471]\n",
      "   [ 0.37921569  0.15019608  0.43254902]\n",
      "   [ 0.54235294  0.32588235  0.24745098]\n",
      "   ..., \n",
      "   [ 0.32588235  0.52039216  0.64588235]\n",
      "   [ 0.12509804  0.31333333  0.22862745]\n",
      "   [ 0.52980392  0.51411765  0.17215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.11882353  0.68352941  0.70862745]\n",
      "   [ 0.39803922  0.27568627  0.27568627]\n",
      "   [ 0.25372549  0.51411765  0.22862745]\n",
      "   ..., \n",
      "   [ 0.72745098  0.20352941  0.15960784]\n",
      "   [ 0.63333333  0.1627451   0.21294118]\n",
      "   [ 0.51098039  0.65843137  0.42      ]]\n",
      "\n",
      "  [[ 0.2254902   0.52980392  0.78392157]\n",
      "   [ 0.69607843  0.11882353  0.40117647]\n",
      "   [ 0.64588235  0.20039216  0.55490196]\n",
      "   ..., \n",
      "   [ 0.78078431  0.1627451   0.24745098]\n",
      "   [ 0.14392157  0.68980392  0.24431373]\n",
      "   [ 0.63333333  0.35098039  0.60196078]]\n",
      "\n",
      "  [[ 0.10627451  0.50156863  0.24431373]\n",
      "   [ 0.28823529  0.67411765  0.34470588]\n",
      "   [ 0.49215686  0.1         0.44823529]\n",
      "   ..., \n",
      "   [ 0.63647059  0.29137255  0.20039216]\n",
      "   [ 0.58313725  0.1627451   0.28196078]\n",
      "   [ 0.60509804  0.22862745  0.45137255]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.76823529  0.62078431  0.33843137]\n",
      "   [ 0.43882353  0.30078431  0.68980392]\n",
      "   [ 0.50156863  0.22235294  0.4545098 ]\n",
      "   ..., \n",
      "   [ 0.74        0.76509804  0.26627451]\n",
      "   [ 0.60823529  0.47333333  0.22862745]\n",
      "   [ 0.13764706  0.58313725  0.86862745]]\n",
      "\n",
      "  [[ 0.22235294  0.79019608  0.10627451]\n",
      "   [ 0.61764706  0.51098039  0.63647059]\n",
      "   [ 0.30078431  0.62705882  0.87490196]\n",
      "   ..., \n",
      "   [ 0.4545098   0.28196078  0.50470588]\n",
      "   [ 0.31019608  0.89686275  0.1345098 ]\n",
      "   [ 0.85921569  0.34784314  0.24117647]]\n",
      "\n",
      "  [[ 0.87803922  0.61764706  0.58313725]\n",
      "   [ 0.63019608  0.33529412  0.79019608]\n",
      "   [ 0.84980392  0.58941176  0.56431373]\n",
      "   ..., \n",
      "   [ 0.30392157  0.57058824  0.87176471]\n",
      "   [ 0.88117647  0.88745098  0.24431373]\n",
      "   [ 0.59568627  0.15333333  0.46392157]]]\n",
      "\n",
      "\n",
      " [[[ 0.48901961  0.67411765  0.81215686]\n",
      "   [ 0.40431373  0.51098039  0.10313725]\n",
      "   [ 0.35098039  0.52039216  0.53294118]\n",
      "   ..., \n",
      "   [ 0.81843137  0.14392157  0.48588235]\n",
      "   [ 0.33215686  0.71490196  0.85921569]\n",
      "   [ 0.23490196  0.75254902  0.71176471]]\n",
      "\n",
      "  [[ 0.48901961  0.80901961  0.74941176]\n",
      "   [ 0.27882353  0.24745098  0.24117647]\n",
      "   [ 0.32588235  0.41372549  0.80901961]\n",
      "   ..., \n",
      "   [ 0.75882353  0.21607843  0.89372549]\n",
      "   [ 0.73058824  0.45137255  0.53607843]\n",
      "   [ 0.44509804  0.18156863  0.25058824]]\n",
      "\n",
      "  [[ 0.73058824  0.3854902   0.59254902]\n",
      "   [ 0.38235294  0.11882353  0.58313725]\n",
      "   [ 0.74313725  0.2254902   0.46705882]\n",
      "   ..., \n",
      "   [ 0.17529412  0.31333333  0.68980392]\n",
      "   [ 0.66784314  0.45764706  0.20666667]\n",
      "   [ 0.36352941  0.52352941  0.58941176]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.80901961  0.33843137  0.59568627]\n",
      "   [ 0.61764706  0.55176471  0.61137255]\n",
      "   [ 0.51098039  0.53921569  0.36039216]\n",
      "   ..., \n",
      "   [ 0.68980392  0.63960784  0.62705882]\n",
      "   [ 0.60196078  0.36980392  0.50470588]\n",
      "   [ 0.43568627  0.62078431  0.79019608]]\n",
      "\n",
      "  [[ 0.49215686  0.75254902  0.81529412]\n",
      "   [ 0.40117647  0.66784314  0.11254902]\n",
      "   [ 0.29137255  0.78392157  0.46392157]\n",
      "   ..., \n",
      "   [ 0.23803922  0.58941176  0.34470588]\n",
      "   [ 0.25372549  0.20352941  0.5172549 ]\n",
      "   [ 0.65843137  0.37921569  0.5172549 ]]\n",
      "\n",
      "  [[ 0.30078431  0.84352941  0.43568627]\n",
      "   [ 0.47019608  0.15019608  0.54235294]\n",
      "   [ 0.39176471  0.63960784  0.89686275]\n",
      "   ..., \n",
      "   [ 0.81215686  0.53921569  0.79333333]\n",
      "   [ 0.59882353  0.71803922  0.54862745]\n",
      "   [ 0.34470588  0.63019608  0.16588235]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.36666667  0.49215686  0.50784314]\n",
      "   [ 0.26        0.22235294  0.25686275]\n",
      "   [ 0.78078431  0.71176471  0.10941176]\n",
      "   ..., \n",
      "   [ 0.62392157  0.78078431  0.10941176]\n",
      "   [ 0.50156863  0.8372549   0.89372549]\n",
      "   [ 0.8654902   0.52666667  0.19411765]]\n",
      "\n",
      "  [[ 0.81843137  0.53921569  0.44823529]\n",
      "   [ 0.7745098   0.68352941  0.72745098]\n",
      "   [ 0.51098039  0.54862745  0.86235294]\n",
      "   ..., \n",
      "   [ 0.63333333  0.25686275  0.5454902 ]\n",
      "   [ 0.40431373  0.7745098   0.14705882]\n",
      "   [ 0.50156863  0.7054902   0.54862745]]\n",
      "\n",
      "  [[ 0.51098039  0.6772549   0.61764706]\n",
      "   [ 0.35411765  0.78392157  0.26627451]\n",
      "   [ 0.29764706  0.54862745  0.49215686]\n",
      "   ..., \n",
      "   [ 0.37294118  0.19098039  0.58      ]\n",
      "   [ 0.81215686  0.73372549  0.85921569]\n",
      "   [ 0.71803922  0.17529412  0.36980392]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.55803922  0.85921569  0.40745098]\n",
      "   [ 0.26313725  0.74        0.25372549]\n",
      "   [ 0.68980392  0.32901961  0.12196078]\n",
      "   ..., \n",
      "   [ 0.78078431  0.18470588  0.53294118]\n",
      "   [ 0.7054902   0.31647059  0.60823529]\n",
      "   [ 0.7054902   0.72117647  0.61764706]]\n",
      "\n",
      "  [[ 0.31960784  0.23176471  0.84980392]\n",
      "   [ 0.82156863  0.39803922  0.10313725]\n",
      "   [ 0.79333333  0.37294118  0.75882353]\n",
      "   ..., \n",
      "   [ 0.40745098  0.8654902   0.78705882]\n",
      "   [ 0.52352941  0.52980392  0.47960784]\n",
      "   [ 0.36980392  0.25058824  0.24745098]]\n",
      "\n",
      "  [[ 0.30392157  0.55803922  0.33529412]\n",
      "   [ 0.67098039  0.38862745  0.6427451 ]\n",
      "   [ 0.42627451  0.33215686  0.1627451 ]\n",
      "   ..., \n",
      "   [ 0.68039216  0.3854902   0.36039216]\n",
      "   [ 0.41686275  0.57058824  0.26313725]\n",
      "   [ 0.28196078  0.82784314  0.66156863]]]\n",
      "\n",
      "\n",
      " [[[ 0.44509804  0.32901961  0.5454902 ]\n",
      "   [ 0.69921569  0.19411765  0.79019608]\n",
      "   [ 0.12196078  0.84039216  0.79333333]\n",
      "   ..., \n",
      "   [ 0.8372549   0.30705882  0.86235294]\n",
      "   [ 0.61137255  0.72117647  0.67411765]\n",
      "   [ 0.78078431  0.13764706  0.46392157]]\n",
      "\n",
      "  [[ 0.58941176  0.39490196  0.77137255]\n",
      "   [ 0.70235294  0.65529412  0.68980392]\n",
      "   [ 0.63960784  0.82784314  0.10941176]\n",
      "   ..., \n",
      "   [ 0.68352941  0.85294118  0.73058824]\n",
      "   [ 0.63647059  0.58627451  0.49215686]\n",
      "   [ 0.84980392  0.39803922  0.11882353]]\n",
      "\n",
      "  [[ 0.15960784  0.26        0.33843137]\n",
      "   [ 0.49529412  0.33529412  0.39803922]\n",
      "   [ 0.75882353  0.49529412  0.74627451]\n",
      "   ..., \n",
      "   [ 0.27882353  0.20352941  0.71803922]\n",
      "   [ 0.77137255  0.66156863  0.47647059]\n",
      "   [ 0.84666667  0.3227451   0.20039216]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.73058824  0.57372549  0.9       ]\n",
      "   [ 0.72745098  0.60823529  0.53607843]\n",
      "   [ 0.20980392  0.9         0.55176471]\n",
      "   ..., \n",
      "   [ 0.85294118  0.42313725  0.63960784]\n",
      "   [ 0.69921569  0.12823529  0.88745098]\n",
      "   [ 0.70235294  0.6427451   0.57686275]]\n",
      "\n",
      "  [[ 0.82156863  0.33529412  0.54235294]\n",
      "   [ 0.43254902  0.79019608  0.45764706]\n",
      "   [ 0.70862745  0.15333333  0.16588235]\n",
      "   ..., \n",
      "   [ 0.71176471  0.83098039  0.42941176]\n",
      "   [ 0.84039216  0.68666667  0.6427451 ]\n",
      "   [ 0.60823529  0.49215686  0.41372549]]\n",
      "\n",
      "  [[ 0.84039216  0.52039216  0.2254902 ]\n",
      "   [ 0.8372549   0.32588235  0.75568627]\n",
      "   [ 0.30705882  0.46078431  0.52980392]\n",
      "   ..., \n",
      "   [ 0.87490196  0.31333333  0.88117647]\n",
      "   [ 0.59254902  0.50784314  0.37921569]\n",
      "   [ 0.40431373  0.79647059  0.15019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.67411765  0.46078431  0.69607843]\n",
      "   [ 0.3854902   0.72745098  0.76196078]\n",
      "   [ 0.66470588  0.33843137  0.47333333]\n",
      "   ..., \n",
      "   [ 0.3227451   0.66784314  0.78705882]\n",
      "   [ 0.60509804  0.56745098  0.65215686]\n",
      "   [ 0.70862745  0.36666667  0.69921569]]\n",
      "\n",
      "  [[ 0.53294118  0.10313725  0.30705882]\n",
      "   [ 0.27882353  0.30392157  0.64588235]\n",
      "   [ 0.47960784  0.72431373  0.87490196]\n",
      "   ..., \n",
      "   [ 0.78705882  0.13764706  0.49843137]\n",
      "   [ 0.35098039  0.38235294  0.87490196]\n",
      "   [ 0.25372549  0.25058824  0.77764706]]\n",
      "\n",
      "  [[ 0.18156863  0.64588235  0.65529412]\n",
      "   [ 0.2254902   0.19411765  0.26      ]\n",
      "   [ 0.52352941  0.75568627  0.47960784]\n",
      "   ..., \n",
      "   [ 0.82156863  0.40117647  0.49215686]\n",
      "   [ 0.18470588  0.88745098  0.40745098]\n",
      "   [ 0.71803922  0.32901961  0.60196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43882353  0.70235294  0.41372549]\n",
      "   [ 0.58        0.35098039  0.1345098 ]\n",
      "   [ 0.79960784  0.69921569  0.17843137]\n",
      "   ..., \n",
      "   [ 0.76823529  0.79960784  0.82156863]\n",
      "   [ 0.29137255  0.22862745  0.71490196]\n",
      "   [ 0.7054902   0.53921569  0.62078431]]\n",
      "\n",
      "  [[ 0.86235294  0.20980392  0.83411765]\n",
      "   [ 0.18784314  0.11254902  0.71176471]\n",
      "   [ 0.25058824  0.49843137  0.26313725]\n",
      "   ..., \n",
      "   [ 0.65529412  0.16901961  0.89058824]\n",
      "   [ 0.79019608  0.20666667  0.11882353]\n",
      "   [ 0.7745098   0.38862745  0.23176471]]\n",
      "\n",
      "  [[ 0.50156863  0.73686275  0.33215686]\n",
      "   [ 0.87803922  0.11882353  0.37607843]\n",
      "   [ 0.18470588  0.2254902   0.79333333]\n",
      "   ..., \n",
      "   [ 0.42        0.26313725  0.28196078]\n",
      "   [ 0.25058824  0.82470588  0.71803922]\n",
      "   [ 0.42941176  0.72117647  0.59882353]]]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    min = 0.1\n",
    "    max = 0.9\n",
    "    thing = max-min\n",
    "\n",
    "    \n",
    "    image_min = 0\n",
    "    image_max = 255\n",
    "    \n",
    "    x = min + (x*thing/255)\n",
    "    print (x)\n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #label = np.array(x)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    # Here the encoder finds the classes and assigns one-hot vectors \n",
    "    lb.fit(x)\n",
    "    \n",
    "    # fix problem with  10 labels\n",
    "    lb.classes_ = np.array(list(range(10)))\n",
    "    # And finally, transform the labels into one-hot encoded vectors\n",
    "    x = lb.transform(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.28509804  0.2945098   0.29764706]\n",
      "   [ 0.23490196  0.24431373  0.24117647]\n",
      "   [ 0.25686275  0.25058824  0.23490196]\n",
      "   ..., \n",
      "   [ 0.59568627  0.51411765  0.43882353]\n",
      "   [ 0.57686275  0.49215686  0.42      ]\n",
      "   [ 0.56431373  0.48901961  0.42313725]]\n",
      "\n",
      "  [[ 0.15019608  0.1627451   0.1627451 ]\n",
      "   [ 0.1         0.1         0.1       ]\n",
      "   [ 0.15647059  0.12509804  0.1       ]\n",
      "   ..., \n",
      "   [ 0.48588235  0.37607843  0.27254902]\n",
      "   [ 0.47333333  0.36039216  0.25686275]\n",
      "   [ 0.4827451   0.37294118  0.27882353]]\n",
      "\n",
      "  [[ 0.17843137  0.17529412  0.16588235]\n",
      "   [ 0.15019608  0.12196078  0.1       ]\n",
      "   [ 0.25372549  0.18470588  0.12509804]\n",
      "   ..., \n",
      "   [ 0.47019608  0.36352941  0.25686275]\n",
      "   [ 0.47647059  0.36352941  0.25686275]\n",
      "   [ 0.44196078  0.32901961  0.23176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.75254902  0.63333333  0.40117647]\n",
      "   [ 0.73058824  0.58        0.20666667]\n",
      "   [ 0.72117647  0.60509804  0.18156863]\n",
      "   ..., \n",
      "   [ 0.60196078  0.5172549   0.31960784]\n",
      "   [ 0.27568627  0.1972549   0.12196078]\n",
      "   [ 0.26627451  0.20666667  0.1627451 ]]\n",
      "\n",
      "  [[ 0.66470588  0.53607843  0.40117647]\n",
      "   [ 0.6427451   0.48588235  0.23176471]\n",
      "   [ 0.68352941  0.55176471  0.19411765]\n",
      "   ..., \n",
      "   [ 0.6772549   0.56431373  0.39490196]\n",
      "   [ 0.40431373  0.2945098   0.20666667]\n",
      "   [ 0.36039216  0.26627451  0.20666667]]\n",
      "\n",
      "  [[ 0.65529412  0.55176471  0.46392157]\n",
      "   [ 0.62705882  0.50470588  0.39490196]\n",
      "   [ 0.66156863  0.5454902   0.37294118]\n",
      "   ..., \n",
      "   [ 0.77764706  0.6772549   0.53921569]\n",
      "   [ 0.57372549  0.47019608  0.36352941]\n",
      "   [ 0.48588235  0.38862745  0.32588235]]]\n",
      "\n",
      "\n",
      " [[[ 0.58313725  0.65529412  0.68666667]\n",
      "   [ 0.49529412  0.52980392  0.52666667]\n",
      "   [ 0.42941176  0.42627451  0.39803922]\n",
      "   ..., \n",
      "   [ 0.3854902   0.39803922  0.3227451 ]\n",
      "   [ 0.37294118  0.38235294  0.3227451 ]\n",
      "   [ 0.34784314  0.35411765  0.31960784]]\n",
      "\n",
      "  [[ 0.53921569  0.60196078  0.63019608]\n",
      "   [ 0.55490196  0.58        0.58313725]\n",
      "   [ 0.49215686  0.49215686  0.47019608]\n",
      "   ..., \n",
      "   [ 0.40117647  0.41058824  0.34470588]\n",
      "   [ 0.34156863  0.35098039  0.2945098 ]\n",
      "   [ 0.3227451   0.32901961  0.29137255]]\n",
      "\n",
      "  [[ 0.53921569  0.58627451  0.6145098 ]\n",
      "   [ 0.53607843  0.55803922  0.56745098]\n",
      "   [ 0.46078431  0.46078431  0.45137255]\n",
      "   ..., \n",
      "   [ 0.34784314  0.3572549   0.30078431]\n",
      "   [ 0.31333333  0.31960784  0.27254902]\n",
      "   [ 0.31019608  0.31647059  0.27254902]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.64901961  0.62392157  0.62078431]\n",
      "   [ 0.58941176  0.58313725  0.60196078]\n",
      "   [ 0.58313725  0.60196078  0.63333333]\n",
      "   ..., \n",
      "   [ 0.23176471  0.20666667  0.21294118]\n",
      "   [ 0.29137255  0.26627451  0.27882353]\n",
      "   [ 0.39176471  0.36039216  0.3854902 ]]\n",
      "\n",
      "  [[ 0.61764706  0.58313725  0.50156863]\n",
      "   [ 0.58941176  0.57686275  0.50784314]\n",
      "   [ 0.59882353  0.60509804  0.5454902 ]\n",
      "   ..., \n",
      "   [ 0.42313725  0.39176471  0.40117647]\n",
      "   [ 0.48588235  0.45764706  0.47647059]\n",
      "   [ 0.51098039  0.47960784  0.51098039]]\n",
      "\n",
      "  [[ 0.61137255  0.56431373  0.47647059]\n",
      "   [ 0.59568627  0.56431373  0.4827451 ]\n",
      "   [ 0.61137255  0.58941176  0.5172549 ]\n",
      "   ..., \n",
      "   [ 0.54862745  0.5172549   0.53607843]\n",
      "   [ 0.54862745  0.52039216  0.5454902 ]\n",
      "   [ 0.54862745  0.5172549   0.55176471]]]\n",
      "\n",
      "\n",
      " [[[ 0.9         0.9         0.9       ]\n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   ..., \n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   [ 0.89372549  0.89372549  0.89372549]]\n",
      "\n",
      "  [[ 0.9         0.9         0.9       ]\n",
      "   [ 0.9         0.9         0.9       ]\n",
      "   [ 0.9         0.9         0.9       ]\n",
      "   ..., \n",
      "   [ 0.9         0.9         0.9       ]\n",
      "   [ 0.9         0.9         0.9       ]\n",
      "   [ 0.9         0.9         0.9       ]]\n",
      "\n",
      "  [[ 0.9         0.9         0.9       ]\n",
      "   [ 0.89686275  0.89686275  0.89686275]\n",
      "   [ 0.89686275  0.89686275  0.89686275]\n",
      "   ..., \n",
      "   [ 0.89686275  0.89686275  0.89686275]\n",
      "   [ 0.89686275  0.89686275  0.89686275]\n",
      "   [ 0.89686275  0.89686275  0.89686275]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.4545098   0.47647059  0.45137255]\n",
      "   [ 0.44823529  0.47019608  0.44823529]\n",
      "   [ 0.42941176  0.45137255  0.43254902]\n",
      "   ..., \n",
      "   [ 0.32588235  0.35411765  0.35098039]\n",
      "   [ 0.32588235  0.35098039  0.34784314]\n",
      "   [ 0.32588235  0.35098039  0.34784314]]\n",
      "\n",
      "  [[ 0.44823529  0.47019608  0.44509804]\n",
      "   [ 0.42627451  0.44823529  0.42627451]\n",
      "   [ 0.41058824  0.43254902  0.40745098]\n",
      "   ..., \n",
      "   [ 0.31333333  0.33529412  0.32901961]\n",
      "   [ 0.31960784  0.33843137  0.33529412]\n",
      "   [ 0.34470588  0.36352941  0.3572549 ]]\n",
      "\n",
      "  [[ 0.43254902  0.4545098   0.42941176]\n",
      "   [ 0.41058824  0.43254902  0.40745098]\n",
      "   [ 0.39803922  0.42        0.39490196]\n",
      "   ..., \n",
      "   [ 0.34470588  0.36666667  0.36039216]\n",
      "   [ 0.34784314  0.36666667  0.36039216]\n",
      "   [ 0.35098039  0.36980392  0.36352941]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.31647059  0.3227451   0.26313725]\n",
      "   [ 0.2945098   0.2945098   0.25372549]\n",
      "   [ 0.28196078  0.27882353  0.25058824]\n",
      "   ..., \n",
      "   [ 0.47019608  0.49215686  0.35098039]\n",
      "   [ 0.47960784  0.49215686  0.32901961]\n",
      "   [ 0.48588235  0.50470588  0.33215686]]\n",
      "\n",
      "  [[ 0.31960784  0.3227451   0.25372549]\n",
      "   [ 0.28509804  0.28196078  0.24745098]\n",
      "   [ 0.26        0.25372549  0.23490196]\n",
      "   ..., \n",
      "   [ 0.48588235  0.48588235  0.36039216]\n",
      "   [ 0.46705882  0.4827451   0.33843137]\n",
      "   [ 0.43254902  0.45137255  0.30392157]]\n",
      "\n",
      "  [[ 0.32901961  0.32588235  0.24745098]\n",
      "   [ 0.30392157  0.29764706  0.24117647]\n",
      "   [ 0.26313725  0.25686275  0.23803922]\n",
      "   ..., \n",
      "   [ 0.47647059  0.47333333  0.34784314]\n",
      "   [ 0.46078431  0.46078431  0.31647059]\n",
      "   [ 0.44196078  0.44823529  0.31333333]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.71490196  0.75882353  0.39803922]\n",
      "   [ 0.73372549  0.76196078  0.44196078]\n",
      "   [ 0.70862745  0.73058824  0.42941176]\n",
      "   ..., \n",
      "   [ 0.72117647  0.7745098   0.38235294]\n",
      "   [ 0.75254902  0.78705882  0.43882353]\n",
      "   [ 0.76509804  0.80588235  0.44823529]]\n",
      "\n",
      "  [[ 0.69607843  0.74627451  0.39490196]\n",
      "   [ 0.69921569  0.74627451  0.39803922]\n",
      "   [ 0.69607843  0.74313725  0.39176471]\n",
      "   ..., \n",
      "   [ 0.72117647  0.77137255  0.39490196]\n",
      "   [ 0.71176471  0.75254902  0.39803922]\n",
      "   [ 0.74627451  0.79019608  0.43568627]]\n",
      "\n",
      "  [[ 0.67411765  0.71176471  0.39176471]\n",
      "   [ 0.6772549   0.71803922  0.40117647]\n",
      "   [ 0.67098039  0.7054902   0.38862745]\n",
      "   ..., \n",
      "   [ 0.7054902   0.74941176  0.3854902 ]\n",
      "   [ 0.69294118  0.74        0.37294118]\n",
      "   [ 0.72117647  0.76196078  0.41372549]]]\n",
      "\n",
      "\n",
      " [[[ 0.59568627  0.59568627  0.59568627]\n",
      "   [ 0.59568627  0.59568627  0.59254902]\n",
      "   [ 0.59568627  0.59882353  0.58313725]\n",
      "   ..., \n",
      "   [ 0.58941176  0.59254902  0.57686275]\n",
      "   [ 0.58941176  0.59254902  0.57686275]\n",
      "   [ 0.58941176  0.58941176  0.57372549]]\n",
      "\n",
      "  [[ 0.59254902  0.59254902  0.59254902]\n",
      "   [ 0.59568627  0.59568627  0.59254902]\n",
      "   [ 0.59254902  0.59254902  0.58627451]\n",
      "   ..., \n",
      "   [ 0.58941176  0.59254902  0.58      ]\n",
      "   [ 0.58941176  0.59254902  0.57686275]\n",
      "   [ 0.58941176  0.58941176  0.57686275]]\n",
      "\n",
      "  [[ 0.58941176  0.58941176  0.58941176]\n",
      "   [ 0.59254902  0.59254902  0.58941176]\n",
      "   [ 0.59254902  0.59254902  0.58627451]\n",
      "   ..., \n",
      "   [ 0.58627451  0.58627451  0.58      ]\n",
      "   [ 0.58627451  0.58627451  0.58      ]\n",
      "   [ 0.58627451  0.58627451  0.58      ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.28196078  0.31333333  0.31333333]\n",
      "   [ 0.2945098   0.32588235  0.33215686]\n",
      "   [ 0.27568627  0.30705882  0.31019608]\n",
      "   ..., \n",
      "   [ 0.2945098   0.31960784  0.34156863]\n",
      "   [ 0.25058824  0.27882353  0.28509804]\n",
      "   [ 0.27882353  0.30705882  0.31333333]]\n",
      "\n",
      "  [[ 0.26313725  0.2945098   0.29137255]\n",
      "   [ 0.28823529  0.31647059  0.3227451 ]\n",
      "   [ 0.23490196  0.26313725  0.26313725]\n",
      "   ..., \n",
      "   [ 0.30705882  0.33843137  0.34784314]\n",
      "   [ 0.27254902  0.30705882  0.31019608]\n",
      "   [ 0.28823529  0.31960784  0.33215686]]\n",
      "\n",
      "  [[ 0.25686275  0.28196078  0.28509804]\n",
      "   [ 0.26        0.27568627  0.27568627]\n",
      "   [ 0.26627451  0.28823529  0.29137255]\n",
      "   ..., \n",
      "   [ 0.24431373  0.26941176  0.26941176]\n",
      "   [ 0.28196078  0.30705882  0.31333333]\n",
      "   [ 0.29137255  0.32588235  0.33215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.71490196  0.63647059  0.51098039]\n",
      "   [ 0.71490196  0.63960784  0.51098039]\n",
      "   [ 0.7054902   0.62705882  0.50156863]\n",
      "   ..., \n",
      "   [ 0.65529412  0.58        0.50784314]\n",
      "   [ 0.63647059  0.56117647  0.48901961]\n",
      "   [ 0.61764706  0.54235294  0.46705882]]\n",
      "\n",
      "  [[ 0.72117647  0.6427451   0.5172549 ]\n",
      "   [ 0.72117647  0.6427451   0.5172549 ]\n",
      "   [ 0.71176471  0.63019608  0.50470588]\n",
      "   ..., \n",
      "   [ 0.65843137  0.58627451  0.51411765]\n",
      "   [ 0.63960784  0.56745098  0.49529412]\n",
      "   [ 0.62392157  0.55176471  0.47647059]]\n",
      "\n",
      "  [[ 0.71490196  0.63647059  0.51411765]\n",
      "   [ 0.71490196  0.63647059  0.51411765]\n",
      "   [ 0.70235294  0.62392157  0.50156863]\n",
      "   ..., \n",
      "   [ 0.65215686  0.58313725  0.51411765]\n",
      "   [ 0.63333333  0.56745098  0.49529412]\n",
      "   [ 0.61764706  0.54862745  0.47960784]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.68980392  0.59568627  0.42313725]\n",
      "   [ 0.68980392  0.60196078  0.42313725]\n",
      "   [ 0.69294118  0.60196078  0.42      ]\n",
      "   ..., \n",
      "   [ 0.74        0.69607843  0.65843137]\n",
      "   [ 0.72745098  0.69294118  0.66156863]\n",
      "   [ 0.71490196  0.67411765  0.64588235]]\n",
      "\n",
      "  [[ 0.69294118  0.59882353  0.42313725]\n",
      "   [ 0.69294118  0.60196078  0.42627451]\n",
      "   [ 0.69607843  0.60509804  0.42      ]\n",
      "   ..., \n",
      "   [ 0.74313725  0.69607843  0.64901961]\n",
      "   [ 0.72745098  0.68666667  0.65215686]\n",
      "   [ 0.71803922  0.67411765  0.6427451 ]]\n",
      "\n",
      "  [[ 0.6772549   0.58313725  0.41372549]\n",
      "   [ 0.6772549   0.58941176  0.41372549]\n",
      "   [ 0.6772549   0.58627451  0.40431373]\n",
      "   ..., \n",
      "   [ 0.72431373  0.67098039  0.61764706]\n",
      "   [ 0.71490196  0.66470588  0.62392157]\n",
      "   [ 0.7054902   0.65529412  0.62078431]]]]\n",
      "[[[[ 0.20980392  0.17843137  0.18156863]\n",
      "   [ 0.18470588  0.16588235  0.16588235]\n",
      "   [ 0.17843137  0.1627451   0.15960784]\n",
      "   ..., \n",
      "   [ 0.51411765  0.50470588  0.50470588]\n",
      "   [ 0.5172549   0.47960784  0.46392157]\n",
      "   [ 0.49529412  0.46078431  0.4545098 ]]\n",
      "\n",
      "  [[ 0.29764706  0.27254902  0.25686275]\n",
      "   [ 0.20039216  0.18470588  0.16588235]\n",
      "   [ 0.15333333  0.14078431  0.12509804]\n",
      "   ..., \n",
      "   [ 0.42        0.39803922  0.37607843]\n",
      "   [ 0.42941176  0.37921569  0.33843137]\n",
      "   [ 0.41372549  0.36980392  0.34156863]]\n",
      "\n",
      "  [[ 0.41058824  0.3854902   0.36352941]\n",
      "   [ 0.25372549  0.24117647  0.21607843]\n",
      "   [ 0.14705882  0.13764706  0.11568627]\n",
      "   ..., \n",
      "   [ 0.24431373  0.23490196  0.22235294]\n",
      "   [ 0.26313725  0.22862745  0.20666667]\n",
      "   [ 0.26313725  0.23803922  0.22862745]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.62078431  0.61764706  0.63647059]\n",
      "   [ 0.6145098   0.61137255  0.62078431]\n",
      "   [ 0.6145098   0.6145098   0.61764706]\n",
      "   ..., \n",
      "   [ 0.6427451   0.63960784  0.63333333]\n",
      "   [ 0.63333333  0.63333333  0.62705882]\n",
      "   [ 0.62392157  0.62392157  0.62392157]]\n",
      "\n",
      "  [[ 0.63019608  0.62705882  0.65215686]\n",
      "   [ 0.63019608  0.62705882  0.6427451 ]\n",
      "   [ 0.62705882  0.62705882  0.63647059]\n",
      "   ..., \n",
      "   [ 0.63960784  0.63647059  0.63333333]\n",
      "   [ 0.62705882  0.62392157  0.62392157]\n",
      "   [ 0.61764706  0.61764706  0.62078431]]\n",
      "\n",
      "  [[ 0.6427451   0.63960784  0.66156863]\n",
      "   [ 0.64901961  0.64588235  0.65843137]\n",
      "   [ 0.6427451   0.6427451   0.64901961]\n",
      "   ..., \n",
      "   [ 0.63333333  0.62705882  0.63019608]\n",
      "   [ 0.62705882  0.62392157  0.62705882]\n",
      "   [ 0.62078431  0.62078431  0.62705882]]]\n",
      "\n",
      "\n",
      " [[[ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.15647059  0.14078431  0.13137255]\n",
      "   ..., \n",
      "   [ 0.1627451   0.15019608  0.15019608]\n",
      "   [ 0.16588235  0.15019608  0.14392157]\n",
      "   [ 0.16588235  0.15019608  0.14078431]]\n",
      "\n",
      "  [[ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.15647059  0.14078431  0.13137255]\n",
      "   ..., \n",
      "   [ 0.1627451   0.15019608  0.14705882]\n",
      "   [ 0.16588235  0.15019608  0.14078431]\n",
      "   [ 0.16588235  0.15019608  0.14078431]]\n",
      "\n",
      "  [[ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.15647059  0.14078431  0.13137255]\n",
      "   ..., \n",
      "   [ 0.1627451   0.15019608  0.14392157]\n",
      "   [ 0.16588235  0.15019608  0.14078431]\n",
      "   [ 0.16588235  0.15019608  0.14078431]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.30705882  0.26941176  0.22862745]\n",
      "   [ 0.35098039  0.31019608  0.26627451]\n",
      "   [ 0.24745098  0.20980392  0.15960784]\n",
      "   ..., \n",
      "   [ 0.52039216  0.52039216  0.41372549]\n",
      "   [ 0.44509804  0.4545098   0.34156863]\n",
      "   [ 0.40745098  0.42        0.30705882]]\n",
      "\n",
      "  [[ 0.28823529  0.25058824  0.20352941]\n",
      "   [ 0.27254902  0.23490196  0.18470588]\n",
      "   [ 0.25686275  0.21921569  0.16901961]\n",
      "   ..., \n",
      "   [ 0.48588235  0.49215686  0.36039216]\n",
      "   [ 0.34784314  0.35411765  0.23176471]\n",
      "   [ 0.32588235  0.33215686  0.21921569]]\n",
      "\n",
      "  [[ 0.30078431  0.26941176  0.21921569]\n",
      "   [ 0.27254902  0.24117647  0.19098039]\n",
      "   [ 0.25058824  0.21921569  0.16588235]\n",
      "   ..., \n",
      "   [ 0.58627451  0.59254902  0.44823529]\n",
      "   [ 0.52666667  0.52980392  0.40431373]\n",
      "   [ 0.37607843  0.37921569  0.26      ]]]\n",
      "\n",
      "\n",
      " [[[ 0.46392157  0.42313725  0.27568627]\n",
      "   [ 0.46078431  0.42941176  0.28509804]\n",
      "   [ 0.58627451  0.50156863  0.3572549 ]\n",
      "   ..., \n",
      "   [ 0.64901961  0.51411765  0.34156863]\n",
      "   [ 0.63019608  0.5172549   0.32588235]\n",
      "   [ 0.5454902   0.47333333  0.26627451]]\n",
      "\n",
      "  [[ 0.46392157  0.42        0.28196078]\n",
      "   [ 0.4827451   0.43882353  0.30392157]\n",
      "   [ 0.58        0.47960784  0.34784314]\n",
      "   ..., \n",
      "   [ 0.57058824  0.44823529  0.27882353]\n",
      "   [ 0.55490196  0.47960784  0.28823529]\n",
      "   [ 0.5172549   0.48588235  0.26941176]]\n",
      "\n",
      "  [[ 0.39803922  0.36980392  0.22862745]\n",
      "   [ 0.40745098  0.36352941  0.23803922]\n",
      "   [ 0.54235294  0.43254902  0.31019608]\n",
      "   ..., \n",
      "   [ 0.55490196  0.45137255  0.28196078]\n",
      "   [ 0.49529412  0.44823529  0.26      ]\n",
      "   [ 0.49843137  0.49215686  0.2945098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.34156863  0.29764706  0.19098039]\n",
      "   [ 0.37607843  0.32588235  0.21607843]\n",
      "   [ 0.31960784  0.28509804  0.18470588]\n",
      "   ..., \n",
      "   [ 0.25058824  0.22235294  0.1627451 ]\n",
      "   [ 0.46392157  0.43882353  0.36352941]\n",
      "   [ 0.59882353  0.5454902   0.4827451 ]]\n",
      "\n",
      "  [[ 0.27254902  0.21607843  0.15019608]\n",
      "   [ 0.30392157  0.24431373  0.17529412]\n",
      "   [ 0.31333333  0.26627451  0.19411765]\n",
      "   ..., \n",
      "   [ 0.23176471  0.19411765  0.14078431]\n",
      "   [ 0.49529412  0.45764706  0.38235294]\n",
      "   [ 0.60196078  0.56117647  0.49215686]]\n",
      "\n",
      "  [[ 0.34470588  0.27882353  0.21607843]\n",
      "   [ 0.32588235  0.25686275  0.19411765]\n",
      "   [ 0.31019608  0.25686275  0.20039216]\n",
      "   ..., \n",
      "   [ 0.26313725  0.21607843  0.15647059]\n",
      "   [ 0.48901961  0.44509804  0.36352941]\n",
      "   [ 0.58627451  0.55176471  0.48901961]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.43254902  0.36980392  0.58941176]\n",
      "   [ 0.48588235  0.42        0.50470588]\n",
      "   [ 0.44823529  0.36666667  0.49215686]\n",
      "   ..., \n",
      "   [ 0.51098039  0.47019608  0.59254902]\n",
      "   [ 0.44196078  0.41372549  0.5454902 ]\n",
      "   [ 0.54235294  0.52352941  0.59568627]]\n",
      "\n",
      "  [[ 0.58627451  0.52039216  0.60823529]\n",
      "   [ 0.63960784  0.55803922  0.4545098 ]\n",
      "   [ 0.51098039  0.44823529  0.48901961]\n",
      "   ..., \n",
      "   [ 0.51411765  0.47333333  0.58627451]\n",
      "   [ 0.41372549  0.37921569  0.50784314]\n",
      "   [ 0.55490196  0.52980392  0.60823529]]\n",
      "\n",
      "  [[ 0.60823529  0.52039216  0.64588235]\n",
      "   [ 0.60196078  0.49843137  0.44509804]\n",
      "   [ 0.4545098   0.37607843  0.52039216]\n",
      "   ..., \n",
      "   [ 0.68666667  0.67098039  0.62392157]\n",
      "   [ 0.65529412  0.63960784  0.62705882]\n",
      "   [ 0.73058824  0.71803922  0.67411765]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.3854902   0.13137255  0.52039216]\n",
      "   [ 0.37607843  0.12823529  0.49843137]\n",
      "   [ 0.37607843  0.14078431  0.49843137]\n",
      "   ..., \n",
      "   [ 0.42627451  0.29764706  0.49529412]\n",
      "   [ 0.44823529  0.32588235  0.5172549 ]\n",
      "   [ 0.45137255  0.30392157  0.52666667]]\n",
      "\n",
      "  [[ 0.33843137  0.11882353  0.50156863]\n",
      "   [ 0.34470588  0.11254902  0.47647059]\n",
      "   [ 0.3854902   0.16588235  0.51411765]\n",
      "   ..., \n",
      "   [ 0.44196078  0.31647059  0.49843137]\n",
      "   [ 0.43568627  0.31333333  0.50784314]\n",
      "   [ 0.45764706  0.29764706  0.53607843]]\n",
      "\n",
      "  [[ 0.31019608  0.12509804  0.50156863]\n",
      "   [ 0.31333333  0.11882353  0.47647059]\n",
      "   [ 0.34784314  0.15647059  0.49843137]\n",
      "   ..., \n",
      "   [ 0.46705882  0.32901961  0.52039216]\n",
      "   [ 0.44509804  0.30078431  0.5172549 ]\n",
      "   [ 0.41058824  0.23176471  0.49215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.87490196  0.87176471  0.87803922]\n",
      "   [ 0.86862745  0.88117647  0.89058824]\n",
      "   [ 0.8654902   0.87803922  0.88117647]\n",
      "   ..., \n",
      "   [ 0.46705882  0.40431373  0.36352941]\n",
      "   [ 0.49843137  0.43568627  0.40117647]\n",
      "   [ 0.59568627  0.55176471  0.53294118]]\n",
      "\n",
      "  [[ 0.86235294  0.8654902   0.87490196]\n",
      "   [ 0.86235294  0.87490196  0.88117647]\n",
      "   [ 0.86235294  0.86862745  0.8654902 ]\n",
      "   ..., \n",
      "   [ 0.4545098   0.3854902   0.33843137]\n",
      "   [ 0.4827451   0.42        0.37607843]\n",
      "   [ 0.60509804  0.55490196  0.52352941]]\n",
      "\n",
      "  [[ 0.8654902   0.86862745  0.88117647]\n",
      "   [ 0.86862745  0.88117647  0.88431373]\n",
      "   [ 0.87490196  0.87490196  0.8654902 ]\n",
      "   ..., \n",
      "   [ 0.52352941  0.44196078  0.39176471]\n",
      "   [ 0.47960784  0.40117647  0.35411765]\n",
      "   [ 0.50470588  0.44509804  0.41058824]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.67098039  0.63019608  0.60823529]\n",
      "   [ 0.72117647  0.68039216  0.65843137]\n",
      "   [ 0.78392157  0.74313725  0.72117647]\n",
      "   ..., \n",
      "   [ 0.59254902  0.53921569  0.4545098 ]\n",
      "   [ 0.39490196  0.34470588  0.27568627]\n",
      "   [ 0.50784314  0.46705882  0.42941176]]\n",
      "\n",
      "  [[ 0.53607843  0.47019608  0.43568627]\n",
      "   [ 0.49529412  0.42313725  0.3854902 ]\n",
      "   [ 0.52039216  0.44823529  0.40745098]\n",
      "   ..., \n",
      "   [ 0.59568627  0.5454902   0.45137255]\n",
      "   [ 0.47333333  0.42627451  0.35098039]\n",
      "   [ 0.46392157  0.42627451  0.38235294]]\n",
      "\n",
      "  [[ 0.71490196  0.66156863  0.60196078]\n",
      "   [ 0.68039216  0.61137255  0.53607843]\n",
      "   [ 0.65215686  0.57058824  0.48588235]\n",
      "   ..., \n",
      "   [ 0.57686275  0.53921569  0.43882353]\n",
      "   [ 0.65529412  0.6145098   0.52980392]\n",
      "   [ 0.60823529  0.57686275  0.5172549 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.69294118  0.81843137  0.85294118]\n",
      "   [ 0.71176471  0.82784314  0.85921569]\n",
      "   [ 0.73686275  0.84666667  0.87176471]\n",
      "   ..., \n",
      "   [ 0.62705882  0.7054902   0.74941176]\n",
      "   [ 0.62705882  0.69921569  0.73372549]\n",
      "   [ 0.62705882  0.68980392  0.72431373]]\n",
      "\n",
      "  [[ 0.73686275  0.84980392  0.87176471]\n",
      "   [ 0.76509804  0.87176471  0.88745098]\n",
      "   [ 0.75882353  0.85921569  0.87490196]\n",
      "   ..., \n",
      "   [ 0.56745098  0.6427451   0.71176471]\n",
      "   [ 0.57372549  0.63960784  0.71176471]\n",
      "   [ 0.58627451  0.6427451   0.71803922]]\n",
      "\n",
      "  [[ 0.76823529  0.87490196  0.88745098]\n",
      "   [ 0.75254902  0.85607843  0.86862745]\n",
      "   [ 0.76196078  0.85607843  0.8654902 ]\n",
      "   ..., \n",
      "   [ 0.56745098  0.63960784  0.71490196]\n",
      "   [ 0.56117647  0.62392157  0.71176471]\n",
      "   [ 0.55176471  0.60509804  0.7054902 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.33215686  0.35411765  0.38235294]\n",
      "   [ 0.26941176  0.3572549   0.4827451 ]\n",
      "   [ 0.22235294  0.42627451  0.59882353]\n",
      "   ..., \n",
      "   [ 0.24431373  0.22235294  0.24431373]\n",
      "   [ 0.25686275  0.23490196  0.26      ]\n",
      "   [ 0.31647059  0.29764706  0.30078431]]\n",
      "\n",
      "  [[ 0.30392157  0.31019608  0.32901961]\n",
      "   [ 0.23176471  0.28196078  0.3854902 ]\n",
      "   [ 0.24117647  0.38862745  0.50784314]\n",
      "   ..., \n",
      "   [ 0.21607843  0.16901961  0.24117647]\n",
      "   [ 0.23803922  0.18470588  0.24745098]\n",
      "   [ 0.27882353  0.23803922  0.26      ]]\n",
      "\n",
      "  [[ 0.26627451  0.28196078  0.29764706]\n",
      "   [ 0.22235294  0.26        0.30392157]\n",
      "   [ 0.29764706  0.34470588  0.39490196]\n",
      "   ..., \n",
      "   [ 0.24431373  0.18156863  0.25372549]\n",
      "   [ 0.28509804  0.21921569  0.24745098]\n",
      "   [ 0.33529412  0.29137255  0.26      ]]]]\n",
      "[[[[ 0.18156863  0.17215686  0.20039216]\n",
      "   [ 0.15333333  0.14392157  0.17843137]\n",
      "   [ 0.14078431  0.12823529  0.17529412]\n",
      "   ..., \n",
      "   [ 0.14705882  0.14392157  0.18784314]\n",
      "   [ 0.17529412  0.17529412  0.21607843]\n",
      "   [ 0.16901961  0.16588235  0.20666667]]\n",
      "\n",
      "  [[ 0.1627451   0.15333333  0.18156863]\n",
      "   [ 0.14078431  0.13137255  0.16901961]\n",
      "   [ 0.14078431  0.12823529  0.17529412]\n",
      "   ..., \n",
      "   [ 0.15960784  0.15333333  0.20980392]\n",
      "   [ 0.16588235  0.1627451   0.20980392]\n",
      "   [ 0.19098039  0.19098039  0.22235294]]\n",
      "\n",
      "  [[ 0.14392157  0.1345098   0.1627451 ]\n",
      "   [ 0.14078431  0.13137255  0.16588235]\n",
      "   [ 0.14078431  0.12823529  0.17215686]\n",
      "   ..., \n",
      "   [ 0.15333333  0.15019608  0.20039216]\n",
      "   [ 0.17843137  0.17529412  0.21921569]\n",
      "   [ 0.1972549   0.1972549   0.23176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.38235294  0.44196078  0.52980392]\n",
      "   [ 0.20666667  0.30078431  0.39803922]\n",
      "   [ 0.18784314  0.26941176  0.38235294]\n",
      "   ..., \n",
      "   [ 0.17215686  0.1627451   0.21607843]\n",
      "   [ 0.15019608  0.14078431  0.19411765]\n",
      "   [ 0.12823529  0.11882353  0.17215686]]\n",
      "\n",
      "  [[ 0.34784314  0.42941176  0.54235294]\n",
      "   [ 0.28196078  0.40117647  0.53607843]\n",
      "   [ 0.20039216  0.31333333  0.44509804]\n",
      "   ..., \n",
      "   [ 0.14392157  0.1345098   0.18784314]\n",
      "   [ 0.15019608  0.14078431  0.19411765]\n",
      "   [ 0.13137255  0.12196078  0.17529412]]\n",
      "\n",
      "  [[ 0.50156863  0.59254902  0.71490196]\n",
      "   [ 0.28196078  0.39176471  0.56745098]\n",
      "   [ 0.17843137  0.28823529  0.43254902]\n",
      "   ..., \n",
      "   [ 0.14078431  0.13137255  0.18470588]\n",
      "   [ 0.13764706  0.12823529  0.18156863]\n",
      "   [ 0.14078431  0.13137255  0.18470588]]]\n",
      "\n",
      "\n",
      " [[[ 0.39490196  0.36980392  0.28196078]\n",
      "   [ 0.41686275  0.3854902   0.29137255]\n",
      "   [ 0.39803922  0.36666667  0.26941176]\n",
      "   ..., \n",
      "   [ 0.55490196  0.53294118  0.43254902]\n",
      "   [ 0.55490196  0.53921569  0.43882353]\n",
      "   [ 0.47960784  0.46705882  0.38235294]]\n",
      "\n",
      "  [[ 0.37921569  0.36352941  0.27254902]\n",
      "   [ 0.40431373  0.37921569  0.28509804]\n",
      "   [ 0.41686275  0.3854902   0.28823529]\n",
      "   ..., \n",
      "   [ 0.55803922  0.52980392  0.43254902]\n",
      "   [ 0.55803922  0.53607843  0.43568627]\n",
      "   [ 0.4827451   0.46705882  0.38235294]]\n",
      "\n",
      "  [[ 0.36980392  0.36352941  0.26941176]\n",
      "   [ 0.39490196  0.37607843  0.27882353]\n",
      "   [ 0.43568627  0.40745098  0.31019608]\n",
      "   ..., \n",
      "   [ 0.55803922  0.52666667  0.43254902]\n",
      "   [ 0.56117647  0.53294118  0.43568627]\n",
      "   [ 0.48588235  0.46392157  0.38235294]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.74313725  0.74313725  0.74      ]\n",
      "   [ 0.75254902  0.75254902  0.74941176]\n",
      "   [ 0.73058824  0.73058824  0.72745098]\n",
      "   ..., \n",
      "   [ 0.55490196  0.56745098  0.56745098]\n",
      "   [ 0.56745098  0.57686275  0.59254902]\n",
      "   [ 0.49215686  0.50156863  0.52352941]]\n",
      "\n",
      "  [[ 0.73058824  0.73058824  0.73058824]\n",
      "   [ 0.74313725  0.74313725  0.74313725]\n",
      "   [ 0.72117647  0.72117647  0.72117647]\n",
      "   ..., \n",
      "   [ 0.58313725  0.59568627  0.63019608]\n",
      "   [ 0.59568627  0.60823529  0.65529412]\n",
      "   [ 0.52039216  0.53294118  0.58      ]]\n",
      "\n",
      "  [[ 0.69607843  0.69607843  0.69294118]\n",
      "   [ 0.68980392  0.68980392  0.68666667]\n",
      "   [ 0.64901961  0.64901961  0.6427451 ]\n",
      "   ..., \n",
      "   [ 0.60823529  0.6145098   0.67098039]\n",
      "   [ 0.61137255  0.62078431  0.6772549 ]\n",
      "   [ 0.52352941  0.52980392  0.58627451]]]\n",
      "\n",
      "\n",
      " [[[ 0.67411765  0.68352941  0.65843137]\n",
      "   [ 0.59568627  0.62392157  0.57686275]\n",
      "   [ 0.62078431  0.63960784  0.60196078]\n",
      "   ..., \n",
      "   [ 0.5454902   0.56117647  0.55176471]\n",
      "   [ 0.52980392  0.55803922  0.54235294]\n",
      "   [ 0.55176471  0.57058824  0.55803922]]\n",
      "\n",
      "  [[ 0.49215686  0.52039216  0.47647059]\n",
      "   [ 0.40431373  0.44823529  0.38235294]\n",
      "   [ 0.41372549  0.45137255  0.39803922]\n",
      "   ..., \n",
      "   [ 0.29764706  0.33215686  0.31333333]\n",
      "   [ 0.28509804  0.33215686  0.31019608]\n",
      "   [ 0.31019608  0.34784314  0.32588235]]\n",
      "\n",
      "  [[ 0.43568627  0.47960784  0.42313725]\n",
      "   [ 0.36666667  0.42627451  0.34784314]\n",
      "   [ 0.37607843  0.42627451  0.36039216]\n",
      "   ..., \n",
      "   [ 0.29764706  0.34784314  0.3227451 ]\n",
      "   [ 0.26627451  0.32901961  0.30078431]\n",
      "   [ 0.28823529  0.34156863  0.31647059]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43882353  0.46392157  0.42313725]\n",
      "   [ 0.40745098  0.43568627  0.37294118]\n",
      "   [ 0.47333333  0.50784314  0.42941176]\n",
      "   ..., \n",
      "   [ 0.45764706  0.49215686  0.4545098 ]\n",
      "   [ 0.42627451  0.46078431  0.42313725]\n",
      "   [ 0.3854902   0.41686275  0.38235294]]\n",
      "\n",
      "  [[ 0.72431373  0.74313725  0.71803922]\n",
      "   [ 0.71803922  0.73686275  0.69607843]\n",
      "   [ 0.74941176  0.77137255  0.71490196]\n",
      "   ..., \n",
      "   [ 0.73686275  0.75568627  0.73372549]\n",
      "   [ 0.72745098  0.74313725  0.72431373]\n",
      "   [ 0.69294118  0.70862745  0.68980392]]\n",
      "\n",
      "  [[ 0.88745098  0.9         0.89058824]\n",
      "   [ 0.87803922  0.89058824  0.87176471]\n",
      "   [ 0.88117647  0.89372549  0.8654902 ]\n",
      "   ..., \n",
      "   [ 0.88431373  0.88745098  0.88431373]\n",
      "   [ 0.88431373  0.88431373  0.88431373]\n",
      "   [ 0.88431373  0.88745098  0.88431373]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.63960784  0.6427451   0.57686275]\n",
      "   [ 0.63647059  0.63960784  0.57686275]\n",
      "   [ 0.65843137  0.65843137  0.59568627]\n",
      "   ..., \n",
      "   [ 0.43568627  0.42941176  0.34156863]\n",
      "   [ 0.43254902  0.42313725  0.34784314]\n",
      "   [ 0.42        0.41058824  0.34470588]]\n",
      "\n",
      "  [[ 0.61764706  0.61137255  0.54862745]\n",
      "   [ 0.59882353  0.59254902  0.53294118]\n",
      "   [ 0.66470588  0.65843137  0.59882353]\n",
      "   ..., \n",
      "   [ 0.46705882  0.45137255  0.36039216]\n",
      "   [ 0.46705882  0.45137255  0.36980392]\n",
      "   [ 0.44823529  0.43254902  0.36039216]]\n",
      "\n",
      "  [[ 0.64588235  0.63019608  0.57058824]\n",
      "   [ 0.58941176  0.57372549  0.51411765]\n",
      "   [ 0.64588235  0.63019608  0.57058824]\n",
      "   ..., \n",
      "   [ 0.47647059  0.45764706  0.36039216]\n",
      "   [ 0.47960784  0.45764706  0.36980392]\n",
      "   [ 0.47333333  0.45137255  0.37607843]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.4827451   0.46705882  0.39490196]\n",
      "   [ 0.47647059  0.46078431  0.39176471]\n",
      "   [ 0.46392157  0.45137255  0.37921569]\n",
      "   ..., \n",
      "   [ 0.48901961  0.49843137  0.41372549]\n",
      "   [ 0.47960784  0.49529412  0.41372549]\n",
      "   [ 0.46705882  0.4827451   0.40431373]]\n",
      "\n",
      "  [[ 0.44823529  0.42941176  0.34470588]\n",
      "   [ 0.45137255  0.43568627  0.36039216]\n",
      "   [ 0.48588235  0.48901961  0.41686275]\n",
      "   ..., \n",
      "   [ 0.4827451   0.46392157  0.36352941]\n",
      "   [ 0.46705882  0.47019608  0.38235294]\n",
      "   [ 0.4545098   0.46705882  0.38235294]]\n",
      "\n",
      "  [[ 0.45137255  0.42941176  0.34156863]\n",
      "   [ 0.46078431  0.43882353  0.36352941]\n",
      "   [ 0.47019608  0.47647059  0.40117647]\n",
      "   ..., \n",
      "   [ 0.48901961  0.46078431  0.35098039]\n",
      "   [ 0.44509804  0.44509804  0.35411765]\n",
      "   [ 0.42        0.43254902  0.34784314]]]\n",
      "\n",
      "\n",
      " [[[ 0.39803922  0.37607843  0.26      ]\n",
      "   [ 0.38862745  0.37607843  0.25372549]\n",
      "   [ 0.3854902   0.37294118  0.25686275]\n",
      "   ..., \n",
      "   [ 0.26627451  0.26313725  0.19411765]\n",
      "   [ 0.26313725  0.26        0.19411765]\n",
      "   [ 0.26941176  0.26941176  0.20039216]]\n",
      "\n",
      "  [[ 0.42        0.39490196  0.26627451]\n",
      "   [ 0.43254902  0.40431373  0.26      ]\n",
      "   [ 0.43568627  0.40745098  0.26941176]\n",
      "   ..., \n",
      "   [ 0.26313725  0.26313725  0.20039216]\n",
      "   [ 0.25372549  0.25058824  0.18470588]\n",
      "   [ 0.28509804  0.28196078  0.20039216]]\n",
      "\n",
      "  [[ 0.43568627  0.40745098  0.26313725]\n",
      "   [ 0.44196078  0.41058824  0.26313725]\n",
      "   [ 0.42941176  0.40431373  0.26313725]\n",
      "   ..., \n",
      "   [ 0.26627451  0.26627451  0.20039216]\n",
      "   [ 0.27254902  0.26627451  0.19411765]\n",
      "   [ 0.2945098   0.28823529  0.20039216]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.40117647  0.38862745  0.28823529]\n",
      "   [ 0.2945098   0.29137255  0.2254902 ]\n",
      "   [ 0.26627451  0.26941176  0.21294118]\n",
      "   ..., \n",
      "   [ 0.25686275  0.25686275  0.20352941]\n",
      "   [ 0.27254902  0.27254902  0.21294118]\n",
      "   [ 0.28823529  0.28196078  0.22235294]]\n",
      "\n",
      "  [[ 0.35098039  0.33843137  0.26      ]\n",
      "   [ 0.28509804  0.28196078  0.22235294]\n",
      "   [ 0.25686275  0.26        0.20352941]\n",
      "   ..., \n",
      "   [ 0.27568627  0.26313725  0.20666667]\n",
      "   [ 0.30078431  0.28823529  0.22235294]\n",
      "   [ 0.30078431  0.28823529  0.21921569]]\n",
      "\n",
      "  [[ 0.24745098  0.24431373  0.20039216]\n",
      "   [ 0.22235294  0.2254902   0.18784314]\n",
      "   [ 0.22235294  0.2254902   0.17843137]\n",
      "   ..., \n",
      "   [ 0.34784314  0.33215686  0.24117647]\n",
      "   [ 0.30078431  0.28509804  0.21921569]\n",
      "   [ 0.29137255  0.27882353  0.21921569]]]\n",
      "\n",
      "\n",
      " [[[ 0.58627451  0.42313725  0.44509804]\n",
      "   [ 0.57686275  0.41372549  0.43568627]\n",
      "   [ 0.58627451  0.42313725  0.44509804]\n",
      "   ..., \n",
      "   [ 0.28509804  0.21921569  0.23803922]\n",
      "   [ 0.27882353  0.2254902   0.24431373]\n",
      "   [ 0.27882353  0.22862745  0.25686275]]\n",
      "\n",
      "  [[ 0.58627451  0.42627451  0.44823529]\n",
      "   [ 0.56431373  0.40431373  0.42627451]\n",
      "   [ 0.58        0.42        0.44196078]\n",
      "   ..., \n",
      "   [ 0.32901961  0.25058824  0.26627451]\n",
      "   [ 0.27568627  0.22235294  0.24117647]\n",
      "   [ 0.27568627  0.22862745  0.25372549]]\n",
      "\n",
      "  [[ 0.58941176  0.42941176  0.45137255]\n",
      "   [ 0.57058824  0.41058824  0.43254902]\n",
      "   [ 0.56431373  0.40431373  0.42627451]\n",
      "   ..., \n",
      "   [ 0.42941176  0.34784314  0.36039216]\n",
      "   [ 0.28509804  0.23176471  0.25058824]\n",
      "   [ 0.26        0.21294118  0.23803922]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.46392157  0.45137255  0.52039216]\n",
      "   [ 0.4545098   0.44823529  0.50784314]\n",
      "   [ 0.4545098   0.4545098   0.50156863]\n",
      "   ..., \n",
      "   [ 0.44196078  0.40431373  0.45764706]\n",
      "   [ 0.32588235  0.29137255  0.33843137]\n",
      "   [ 0.43882353  0.40117647  0.44823529]]\n",
      "\n",
      "  [[ 0.46392157  0.4545098   0.5172549 ]\n",
      "   [ 0.45764706  0.44823529  0.50784314]\n",
      "   [ 0.46078431  0.45137255  0.51098039]\n",
      "   ..., \n",
      "   [ 0.44509804  0.42941176  0.48901961]\n",
      "   [ 0.28509804  0.25686275  0.31333333]\n",
      "   [ 0.33529412  0.29137255  0.34784314]]\n",
      "\n",
      "  [[ 0.47333333  0.46392157  0.52352941]\n",
      "   [ 0.46392157  0.4545098   0.51411765]\n",
      "   [ 0.46392157  0.4545098   0.51411765]\n",
      "   ..., \n",
      "   [ 0.47647059  0.46705882  0.52980392]\n",
      "   [ 0.41686275  0.39803922  0.45764706]\n",
      "   [ 0.29764706  0.25686275  0.31333333]]]]\n",
      "[[[[ 0.65843137  0.65215686  0.69294118]\n",
      "   [ 0.65843137  0.65215686  0.69294118]\n",
      "   [ 0.65843137  0.65215686  0.69294118]\n",
      "   ..., \n",
      "   [ 0.63333333  0.62705882  0.66470588]\n",
      "   [ 0.62705882  0.62078431  0.65529412]\n",
      "   [ 0.61764706  0.61137255  0.64588235]]\n",
      "\n",
      "  [[ 0.66470588  0.65843137  0.69921569]\n",
      "   [ 0.66156863  0.65529412  0.69607843]\n",
      "   [ 0.66470588  0.65843137  0.69921569]\n",
      "   ..., \n",
      "   [ 0.6427451   0.63647059  0.67098039]\n",
      "   [ 0.63647059  0.63019608  0.66470588]\n",
      "   [ 0.62705882  0.62078431  0.65529412]]\n",
      "\n",
      "  [[ 0.65529412  0.64901961  0.68980392]\n",
      "   [ 0.65529412  0.64901961  0.68980392]\n",
      "   [ 0.65843137  0.65215686  0.69294118]\n",
      "   ..., \n",
      "   [ 0.63647059  0.63019608  0.66470588]\n",
      "   [ 0.63019608  0.62392157  0.65843137]\n",
      "   [ 0.62392157  0.61764706  0.65215686]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.45137255  0.43568627  0.43568627]\n",
      "   [ 0.4545098   0.44196078  0.43882353]\n",
      "   [ 0.45764706  0.44509804  0.44509804]\n",
      "   ..., \n",
      "   [ 0.41372549  0.40431373  0.39490196]\n",
      "   [ 0.40745098  0.39490196  0.39176471]\n",
      "   [ 0.41686275  0.39803922  0.39803922]]\n",
      "\n",
      "  [[ 0.45137255  0.42        0.41686275]\n",
      "   [ 0.45137255  0.42313725  0.42      ]\n",
      "   [ 0.4545098   0.42313725  0.42313725]\n",
      "   ..., \n",
      "   [ 0.42        0.39803922  0.39176471]\n",
      "   [ 0.42        0.39176471  0.3854902 ]\n",
      "   [ 0.42        0.38862745  0.3854902 ]]\n",
      "\n",
      "  [[ 0.42313725  0.40117647  0.38862745]\n",
      "   [ 0.41372549  0.39176471  0.38235294]\n",
      "   [ 0.42313725  0.39803922  0.39490196]\n",
      "   ..., \n",
      "   [ 0.38862745  0.36352941  0.35098039]\n",
      "   [ 0.39176471  0.36980392  0.35098039]\n",
      "   [ 0.3854902   0.36352941  0.34156863]]]\n",
      "\n",
      "\n",
      " [[[ 0.19098039  0.23490196  0.13137255]\n",
      "   [ 0.16901961  0.21294118  0.11254902]\n",
      "   [ 0.17843137  0.21607843  0.15019608]\n",
      "   ..., \n",
      "   [ 0.71803922  0.78705882  0.52980392]\n",
      "   [ 0.72117647  0.78705882  0.52980392]\n",
      "   [ 0.72431373  0.79647059  0.53921569]]\n",
      "\n",
      "  [[ 0.1972549   0.24431373  0.12823529]\n",
      "   [ 0.18470588  0.22862745  0.11882353]\n",
      "   [ 0.15333333  0.19098039  0.11882353]\n",
      "   ..., \n",
      "   [ 0.75882353  0.82784314  0.56431373]\n",
      "   [ 0.75568627  0.82470588  0.56431373]\n",
      "   [ 0.75568627  0.82470588  0.56431373]]\n",
      "\n",
      "  [[ 0.2254902   0.27254902  0.15019608]\n",
      "   [ 0.1972549   0.24117647  0.12509804]\n",
      "   [ 0.1627451   0.20352941  0.12196078]\n",
      "   ..., \n",
      "   [ 0.75882353  0.82784314  0.57058824]\n",
      "   [ 0.75882353  0.82784314  0.56745098]\n",
      "   [ 0.75882353  0.82784314  0.56745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.24117647  0.21921569  0.17215686]\n",
      "   [ 0.17529412  0.16588235  0.1345098 ]\n",
      "   [ 0.15019608  0.14392157  0.12196078]\n",
      "   ..., \n",
      "   [ 0.17843137  0.19098039  0.20039216]\n",
      "   [ 0.17529412  0.18784314  0.1972549 ]\n",
      "   [ 0.17529412  0.18784314  0.1972549 ]]\n",
      "\n",
      "  [[ 0.16588235  0.15647059  0.12196078]\n",
      "   [ 0.15647059  0.14078431  0.10941176]\n",
      "   [ 0.18470588  0.15019608  0.11568627]\n",
      "   ..., \n",
      "   [ 0.18156863  0.19411765  0.20352941]\n",
      "   [ 0.19098039  0.20352941  0.21294118]\n",
      "   [ 0.18784314  0.20039216  0.20980392]]\n",
      "\n",
      "  [[ 0.26627451  0.2254902   0.17215686]\n",
      "   [ 0.35411765  0.2945098   0.21921569]\n",
      "   [ 0.40431373  0.31960784  0.23490196]\n",
      "   ..., \n",
      "   [ 0.16901961  0.18156863  0.19098039]\n",
      "   [ 0.17529412  0.18784314  0.1972549 ]\n",
      "   [ 0.17215686  0.18470588  0.19411765]]]\n",
      "\n",
      "\n",
      " [[[ 0.21294118  0.30392157  0.42      ]\n",
      "   [ 0.20352941  0.27254902  0.43882353]\n",
      "   [ 0.16588235  0.24745098  0.47019608]\n",
      "   ..., \n",
      "   [ 0.18156863  0.20039216  0.2254902 ]\n",
      "   [ 0.18156863  0.1972549   0.1972549 ]\n",
      "   [ 0.19098039  0.19098039  0.1972549 ]]\n",
      "\n",
      "  [[ 0.27254902  0.43568627  0.47647059]\n",
      "   [ 0.24745098  0.39490196  0.43882353]\n",
      "   [ 0.14705882  0.29764706  0.4545098 ]\n",
      "   ..., \n",
      "   [ 0.16901961  0.26        0.42941176]\n",
      "   [ 0.17215686  0.25372549  0.41372549]\n",
      "   [ 0.16588235  0.24431373  0.40431373]]\n",
      "\n",
      "  [[ 0.3572549   0.46392157  0.45764706]\n",
      "   [ 0.39490196  0.49843137  0.42      ]\n",
      "   [ 0.34784314  0.46705882  0.43882353]\n",
      "   ..., \n",
      "   [ 0.24745098  0.36039216  0.58      ]\n",
      "   [ 0.24745098  0.36980392  0.58941176]\n",
      "   [ 0.24117647  0.36666667  0.58      ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.59882353  0.60196078  0.56431373]\n",
      "   [ 0.60823529  0.59882353  0.56745098]\n",
      "   [ 0.62078431  0.60196078  0.57372549]\n",
      "   ..., \n",
      "   [ 0.68666667  0.66470588  0.65529412]\n",
      "   [ 0.68039216  0.65215686  0.64588235]\n",
      "   [ 0.67411765  0.64588235  0.63960784]]\n",
      "\n",
      "  [[ 0.62078431  0.63019608  0.60196078]\n",
      "   [ 0.63333333  0.63019608  0.60509804]\n",
      "   [ 0.6427451   0.63019608  0.60823529]\n",
      "   ..., \n",
      "   [ 0.67411765  0.65215686  0.64588235]\n",
      "   [ 0.66784314  0.6427451   0.63647059]\n",
      "   [ 0.66470588  0.63960784  0.63647059]]\n",
      "\n",
      "  [[ 0.62705882  0.64588235  0.62078431]\n",
      "   [ 0.63647059  0.6427451   0.62392157]\n",
      "   [ 0.64901961  0.6427451   0.62705882]\n",
      "   ..., \n",
      "   [ 0.67098039  0.65215686  0.6427451 ]\n",
      "   [ 0.66784314  0.63960784  0.63333333]\n",
      "   [ 0.66470588  0.63960784  0.63333333]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.31647059  0.37607843  0.45764706]\n",
      "   [ 0.38235294  0.47960784  0.57058824]\n",
      "   [ 0.38235294  0.49843137  0.59568627]\n",
      "   ..., \n",
      "   [ 0.10627451  0.10941176  0.15647059]\n",
      "   [ 0.10627451  0.10627451  0.15019608]\n",
      "   [ 0.10627451  0.10627451  0.14705882]]\n",
      "\n",
      "  [[ 0.19098039  0.22235294  0.30078431]\n",
      "   [ 0.14705882  0.18470588  0.26627451]\n",
      "   [ 0.14078431  0.17843137  0.26      ]\n",
      "   ..., \n",
      "   [ 0.10313725  0.1         0.10627451]\n",
      "   [ 0.1         0.1         0.10313725]\n",
      "   [ 0.1         0.10313725  0.10627451]]\n",
      "\n",
      "  [[ 0.11254902  0.10941176  0.11568627]\n",
      "   [ 0.11254902  0.10313725  0.10627451]\n",
      "   [ 0.10941176  0.10313725  0.10627451]\n",
      "   ..., \n",
      "   [ 0.1         0.1         0.10313725]\n",
      "   [ 0.1         0.1         0.10627451]\n",
      "   [ 0.1         0.1         0.10941176]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.10313725  0.10313725  0.11568627]\n",
      "   [ 0.1         0.1         0.10313725]\n",
      "   [ 0.1         0.1         0.1       ]\n",
      "   ..., \n",
      "   [ 0.13137255  0.12509804  0.1345098 ]\n",
      "   [ 0.10627451  0.10627451  0.11254902]\n",
      "   [ 0.10313725  0.10313725  0.11254902]]\n",
      "\n",
      "  [[ 0.12509804  0.15019608  0.20352941]\n",
      "   [ 0.10313725  0.11254902  0.14078431]\n",
      "   [ 0.1         0.10313725  0.10941176]\n",
      "   ..., \n",
      "   [ 0.12196078  0.13137255  0.17215686]\n",
      "   [ 0.10941176  0.11254902  0.13137255]\n",
      "   [ 0.10313725  0.10313725  0.10941176]]\n",
      "\n",
      "  [[ 0.21607843  0.30078431  0.43882353]\n",
      "   [ 0.17529412  0.23490196  0.34156863]\n",
      "   [ 0.13137255  0.15960784  0.22235294]\n",
      "   ..., \n",
      "   [ 0.1627451   0.19411765  0.29137255]\n",
      "   [ 0.14078431  0.1627451   0.23490196]\n",
      "   [ 0.11882353  0.13137255  0.17215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.68039216  0.73372549  0.74941176]\n",
      "   [ 0.6427451   0.72117647  0.74313725]\n",
      "   [ 0.65215686  0.74941176  0.78078431]\n",
      "   ..., \n",
      "   [ 0.21607843  0.24117647  0.2945098 ]\n",
      "   [ 0.18156863  0.20980392  0.26      ]\n",
      "   [ 0.20352941  0.25686275  0.31647059]]\n",
      "\n",
      "  [[ 0.44196078  0.47647059  0.47333333]\n",
      "   [ 0.47019608  0.52352941  0.52352941]\n",
      "   [ 0.47960784  0.54862745  0.55176471]\n",
      "   ..., \n",
      "   [ 0.23490196  0.25686275  0.28823529]\n",
      "   [ 0.20352941  0.20666667  0.23490196]\n",
      "   [ 0.2254902   0.25058824  0.28196078]]\n",
      "\n",
      "  [[ 0.26313725  0.28196078  0.27254902]\n",
      "   [ 0.28196078  0.31333333  0.30078431]\n",
      "   [ 0.28196078  0.32588235  0.31019608]\n",
      "   ..., \n",
      "   [ 0.24431373  0.28196078  0.31333333]\n",
      "   [ 0.2254902   0.24745098  0.28196078]\n",
      "   [ 0.24745098  0.28196078  0.31333333]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.60823529  0.60196078  0.63960784]\n",
      "   [ 0.59568627  0.58941176  0.62392157]\n",
      "   [ 0.59882353  0.59254902  0.62705882]\n",
      "   ..., \n",
      "   [ 0.14705882  0.14078431  0.17215686]\n",
      "   [ 0.14392157  0.13764706  0.17215686]\n",
      "   [ 0.15647059  0.15019608  0.18470588]]\n",
      "\n",
      "  [[ 0.58941176  0.58313725  0.62705882]\n",
      "   [ 0.57686275  0.57058824  0.61137255]\n",
      "   [ 0.57686275  0.57058824  0.61137255]\n",
      "   ..., \n",
      "   [ 0.14078431  0.1345098   0.16588235]\n",
      "   [ 0.14705882  0.14078431  0.17529412]\n",
      "   [ 0.20039216  0.19411765  0.22862745]]\n",
      "\n",
      "  [[ 0.56745098  0.56117647  0.60509804]\n",
      "   [ 0.55176471  0.5454902   0.58941176]\n",
      "   [ 0.55803922  0.55176471  0.59568627]\n",
      "   ..., \n",
      "   [ 0.15019608  0.14392157  0.17529412]\n",
      "   [ 0.26313725  0.25686275  0.29137255]\n",
      "   [ 0.40745098  0.40117647  0.43568627]]]\n",
      "\n",
      "\n",
      " [[[ 0.71176471  0.67411765  0.63647059]\n",
      "   [ 0.7054902   0.66784314  0.63019608]\n",
      "   [ 0.70862745  0.67098039  0.63333333]\n",
      "   ..., \n",
      "   [ 0.27882353  0.27882353  0.27882353]\n",
      "   [ 0.26313725  0.26313725  0.26313725]\n",
      "   [ 0.12509804  0.12509804  0.12509804]]\n",
      "\n",
      "  [[ 0.71803922  0.6772549   0.6427451 ]\n",
      "   [ 0.71176471  0.67411765  0.63960784]\n",
      "   [ 0.71803922  0.68039216  0.64588235]\n",
      "   ..., \n",
      "   [ 0.37294118  0.37294118  0.37294118]\n",
      "   [ 0.35098039  0.35098039  0.35098039]\n",
      "   [ 0.13137255  0.13137255  0.13137255]]\n",
      "\n",
      "  [[ 0.71803922  0.6772549   0.64901961]\n",
      "   [ 0.71490196  0.67411765  0.64588235]\n",
      "   [ 0.72117647  0.68039216  0.65529412]\n",
      "   ..., \n",
      "   [ 0.44509804  0.44509804  0.44509804]\n",
      "   [ 0.43254902  0.43254902  0.43254902]\n",
      "   [ 0.13764706  0.13764706  0.13764706]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.72431373  0.68039216  0.65529412]\n",
      "   [ 0.71490196  0.6772549   0.64901961]\n",
      "   [ 0.72431373  0.69294118  0.65843137]\n",
      "   ..., \n",
      "   [ 0.20666667  0.18784314  0.16588235]\n",
      "   [ 0.18784314  0.17215686  0.15647059]\n",
      "   [ 0.16901961  0.15960784  0.15019608]]\n",
      "\n",
      "  [[ 0.71803922  0.68039216  0.65215686]\n",
      "   [ 0.71176471  0.67411765  0.64588235]\n",
      "   [ 0.71803922  0.68352941  0.65529412]\n",
      "   ..., \n",
      "   [ 0.22235294  0.1972549   0.16588235]\n",
      "   [ 0.21607843  0.1972549   0.16901961]\n",
      "   [ 0.20980392  0.19098039  0.16901961]]\n",
      "\n",
      "  [[ 0.7054902   0.67411765  0.64588235]\n",
      "   [ 0.7054902   0.66470588  0.63960784]\n",
      "   [ 0.71176471  0.66784314  0.6427451 ]\n",
      "   ..., \n",
      "   [ 0.23176471  0.20352941  0.16588235]\n",
      "   [ 0.23490196  0.20352941  0.17215686]\n",
      "   [ 0.22862745  0.20039216  0.17529412]]]]\n",
      "[[[[ 0.9         0.9         0.89686275]\n",
      "   [ 0.89058824  0.89058824  0.89058824]\n",
      "   [ 0.89372549  0.89058824  0.89686275]\n",
      "   ..., \n",
      "   [ 0.61764706  0.65529412  0.6772549 ]\n",
      "   [ 0.86235294  0.87176471  0.87490196]\n",
      "   [ 0.89686275  0.89372549  0.89058824]]\n",
      "\n",
      "  [[ 0.9         0.9         0.89686275]\n",
      "   [ 0.89058824  0.89058824  0.89058824]\n",
      "   [ 0.89686275  0.89686275  0.9       ]\n",
      "   ..., \n",
      "   [ 0.50784314  0.55176471  0.60509804]\n",
      "   [ 0.80588235  0.82784314  0.84980392]\n",
      "   [ 0.89372549  0.9         0.9       ]]\n",
      "\n",
      "  [[ 0.9         0.9         0.9       ]\n",
      "   [ 0.89686275  0.89686275  0.89686275]\n",
      "   [ 0.87803922  0.87490196  0.88117647]\n",
      "   ..., \n",
      "   [ 0.54235294  0.58627451  0.64901961]\n",
      "   [ 0.79019608  0.81215686  0.8372549 ]\n",
      "   [ 0.89372549  0.9         0.9       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.83098039  0.83411765  0.83411765]\n",
      "   [ 0.77764706  0.77764706  0.77764706]\n",
      "   [ 0.85607843  0.85607843  0.85607843]\n",
      "   ..., \n",
      "   [ 0.12823529  0.1345098   0.1345098 ]\n",
      "   [ 0.15647059  0.15960784  0.15960784]\n",
      "   [ 0.63019608  0.63647059  0.63333333]]\n",
      "\n",
      "  [[ 0.9         0.9         0.9       ]\n",
      "   [ 0.9         0.9         0.9       ]\n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   ..., \n",
      "   [ 0.16588235  0.17215686  0.16901961]\n",
      "   [ 0.4545098   0.46078431  0.45764706]\n",
      "   [ 0.8372549   0.84352941  0.84039216]]\n",
      "\n",
      "  [[ 0.9         0.9         0.9       ]\n",
      "   [ 0.88745098  0.88745098  0.88745098]\n",
      "   [ 0.89372549  0.89372549  0.89372549]\n",
      "   ..., \n",
      "   [ 0.63960784  0.64588235  0.6427451 ]\n",
      "   [ 0.82156863  0.82784314  0.82470588]\n",
      "   [ 0.87490196  0.87803922  0.87803922]]]\n",
      "\n",
      "\n",
      " [[[ 0.49843137  0.55490196  0.62392157]\n",
      "   [ 0.49529412  0.55176471  0.62078431]\n",
      "   [ 0.49843137  0.55490196  0.62392157]\n",
      "   ..., \n",
      "   [ 0.49215686  0.5454902   0.59882353]\n",
      "   [ 0.49215686  0.5454902   0.59882353]\n",
      "   [ 0.48901961  0.54235294  0.59568627]]\n",
      "\n",
      "  [[ 0.49215686  0.54862745  0.6145098 ]\n",
      "   [ 0.49215686  0.54862745  0.61137255]\n",
      "   [ 0.49529412  0.55176471  0.6145098 ]\n",
      "   ..., \n",
      "   [ 0.49215686  0.5454902   0.59254902]\n",
      "   [ 0.48901961  0.5454902   0.58941176]\n",
      "   [ 0.48901961  0.54235294  0.58941176]]\n",
      "\n",
      "  [[ 0.49529412  0.55490196  0.60823529]\n",
      "   [ 0.48901961  0.54862745  0.60196078]\n",
      "   [ 0.49529412  0.55490196  0.60823529]\n",
      "   ..., \n",
      "   [ 0.48901961  0.54862745  0.58941176]\n",
      "   [ 0.48588235  0.54235294  0.58627451]\n",
      "   [ 0.48588235  0.54235294  0.58627451]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.36352941  0.42627451  0.47019608]\n",
      "   [ 0.36666667  0.42627451  0.47019608]\n",
      "   [ 0.37294118  0.43254902  0.47647059]\n",
      "   ..., \n",
      "   [ 0.30392157  0.36039216  0.39803922]\n",
      "   [ 0.34784314  0.40431373  0.44196078]\n",
      "   [ 0.37607843  0.43254902  0.47019608]]\n",
      "\n",
      "  [[ 0.36980392  0.42941176  0.47647059]\n",
      "   [ 0.36039216  0.42        0.46392157]\n",
      "   [ 0.36039216  0.42        0.46392157]\n",
      "   ..., \n",
      "   [ 0.32901961  0.3854902   0.42313725]\n",
      "   [ 0.36039216  0.41686275  0.4545098 ]\n",
      "   [ 0.37294118  0.42941176  0.46705882]]\n",
      "\n",
      "  [[ 0.36666667  0.42627451  0.47019608]\n",
      "   [ 0.36666667  0.42313725  0.46705882]\n",
      "   [ 0.36039216  0.42        0.46392157]\n",
      "   ..., \n",
      "   [ 0.32588235  0.38235294  0.42      ]\n",
      "   [ 0.34470588  0.40117647  0.43882353]\n",
      "   [ 0.3572549   0.41372549  0.45137255]]]\n",
      "\n",
      "\n",
      " [[[ 0.46392157  0.3227451   0.18156863]\n",
      "   [ 0.30078431  0.20666667  0.13137255]\n",
      "   [ 0.15960784  0.11882353  0.10627451]\n",
      "   ..., \n",
      "   [ 0.56431373  0.36352941  0.21921569]\n",
      "   [ 0.63019608  0.40117647  0.24431373]\n",
      "   [ 0.68980392  0.45764706  0.28509804]]\n",
      "\n",
      "  [[ 0.45764706  0.31333333  0.16901961]\n",
      "   [ 0.30078431  0.20980392  0.1345098 ]\n",
      "   [ 0.15647059  0.11882353  0.10627451]\n",
      "   ..., \n",
      "   [ 0.56745098  0.36352941  0.23490196]\n",
      "   [ 0.61137255  0.39490196  0.24117647]\n",
      "   [ 0.68039216  0.45764706  0.28509804]]\n",
      "\n",
      "  [[ 0.45764706  0.30705882  0.17215686]\n",
      "   [ 0.2945098   0.20666667  0.1345098 ]\n",
      "   [ 0.15333333  0.11882353  0.10627451]\n",
      "   ..., \n",
      "   [ 0.59254902  0.38235294  0.24745098]\n",
      "   [ 0.64901961  0.42        0.26      ]\n",
      "   [ 0.68039216  0.45764706  0.28196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.85607843  0.85294118  0.83411765]\n",
      "   [ 0.86235294  0.85921569  0.84039216]\n",
      "   [ 0.85607843  0.85607843  0.84039216]\n",
      "   ..., \n",
      "   [ 0.1972549   0.15647059  0.11254902]\n",
      "   [ 0.20980392  0.1627451   0.11568627]\n",
      "   [ 0.22235294  0.1627451   0.11568627]]\n",
      "\n",
      "  [[ 0.7745098   0.76196078  0.73058824]\n",
      "   [ 0.82156863  0.81215686  0.79019608]\n",
      "   [ 0.84352941  0.8372549   0.82156863]\n",
      "   ..., \n",
      "   [ 0.17215686  0.14078431  0.10941176]\n",
      "   [ 0.17843137  0.14078431  0.10627451]\n",
      "   [ 0.18156863  0.14078431  0.10941176]]\n",
      "\n",
      "  [[ 0.47647059  0.43882353  0.39803922]\n",
      "   [ 0.53294118  0.49843137  0.46078431]\n",
      "   [ 0.58627451  0.55803922  0.52039216]\n",
      "   ..., \n",
      "   [ 0.23803922  0.17843137  0.12196078]\n",
      "   [ 0.22862745  0.16901961  0.11882353]\n",
      "   [ 0.21921569  0.15960784  0.11568627]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.29137255  0.32901961  0.33843137]\n",
      "   [ 0.24431373  0.28196078  0.31333333]\n",
      "   [ 0.22235294  0.25372549  0.30705882]\n",
      "   ..., \n",
      "   [ 0.3227451   0.38235294  0.35098039]\n",
      "   [ 0.2945098   0.34470588  0.33529412]\n",
      "   [ 0.24117647  0.28196078  0.29137255]]\n",
      "\n",
      "  [[ 0.29764706  0.33529412  0.34156863]\n",
      "   [ 0.24117647  0.28196078  0.31019608]\n",
      "   [ 0.20039216  0.23490196  0.28196078]\n",
      "   ..., \n",
      "   [ 0.32901961  0.37921569  0.3572549 ]\n",
      "   [ 0.3227451   0.36352941  0.35098039]\n",
      "   [ 0.25686275  0.28823529  0.2945098 ]]\n",
      "\n",
      "  [[ 0.29764706  0.35098039  0.34156863]\n",
      "   [ 0.27882353  0.33529412  0.33529412]\n",
      "   [ 0.29764706  0.34784314  0.35411765]\n",
      "   ..., \n",
      "   [ 0.3572549   0.40117647  0.3854902 ]\n",
      "   [ 0.33843137  0.37607843  0.3572549 ]\n",
      "   [ 0.26627451  0.29764706  0.2945098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.51098039  0.5172549   0.42      ]\n",
      "   [ 0.58941176  0.58313725  0.47019608]\n",
      "   [ 0.60509804  0.59254902  0.47960784]\n",
      "   ..., \n",
      "   [ 0.83411765  0.79960784  0.6427451 ]\n",
      "   [ 0.79019608  0.74        0.58941176]\n",
      "   [ 0.66784314  0.62078431  0.49529412]]\n",
      "\n",
      "  [[ 0.42941176  0.43882353  0.36039216]\n",
      "   [ 0.43568627  0.43882353  0.34784314]\n",
      "   [ 0.46078431  0.46078431  0.36352941]\n",
      "   ..., \n",
      "   [ 0.8372549   0.79333333  0.63960784]\n",
      "   [ 0.81843137  0.75254902  0.60509804]\n",
      "   [ 0.69921569  0.63333333  0.51098039]]\n",
      "\n",
      "  [[ 0.31019608  0.33215686  0.29137255]\n",
      "   [ 0.34470588  0.36039216  0.31333333]\n",
      "   [ 0.45137255  0.46078431  0.38235294]\n",
      "   ..., \n",
      "   [ 0.81215686  0.74627451  0.57058824]\n",
      "   [ 0.78078431  0.70235294  0.53607843]\n",
      "   [ 0.6772549   0.60196078  0.46705882]]]\n",
      "\n",
      "\n",
      " [[[ 0.13137255  0.11254902  0.14392157]\n",
      "   [ 0.1345098   0.11882353  0.14705882]\n",
      "   [ 0.1627451   0.16901961  0.17215686]\n",
      "   ..., \n",
      "   [ 0.28509804  0.3227451   0.27254902]\n",
      "   [ 0.27882353  0.31960784  0.27254902]\n",
      "   [ 0.26627451  0.31333333  0.28509804]]\n",
      "\n",
      "  [[ 0.13137255  0.11254902  0.14392157]\n",
      "   [ 0.1345098   0.12823529  0.14705882]\n",
      "   [ 0.17843137  0.20039216  0.18784314]\n",
      "   ..., \n",
      "   [ 0.27254902  0.29137255  0.25058824]\n",
      "   [ 0.30705882  0.33843137  0.28196078]\n",
      "   [ 0.25058824  0.29764706  0.26941176]]\n",
      "\n",
      "  [[ 0.13764706  0.11882353  0.15019608]\n",
      "   [ 0.1345098   0.13137255  0.14705882]\n",
      "   [ 0.21921569  0.24745098  0.21921569]\n",
      "   ..., \n",
      "   [ 0.24745098  0.26313725  0.23176471]\n",
      "   [ 0.27882353  0.30705882  0.25372549]\n",
      "   [ 0.26313725  0.30078431  0.26      ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.65529412  0.63019608  0.67411765]\n",
      "   [ 0.66470588  0.63019608  0.6772549 ]\n",
      "   [ 0.6772549   0.63960784  0.69607843]\n",
      "   ..., \n",
      "   [ 0.63960784  0.59882353  0.64588235]\n",
      "   [ 0.63333333  0.59254902  0.63647059]\n",
      "   [ 0.6145098   0.57058824  0.61764706]]\n",
      "\n",
      "  [[ 0.59882353  0.59254902  0.65215686]\n",
      "   [ 0.60823529  0.59254902  0.65529412]\n",
      "   [ 0.62392157  0.60823529  0.67411765]\n",
      "   ..., \n",
      "   [ 0.6772549   0.65843137  0.72745098]\n",
      "   [ 0.66784314  0.64901961  0.71803922]\n",
      "   [ 0.65843137  0.6427451   0.71176471]]\n",
      "\n",
      "  [[ 0.59568627  0.59568627  0.68352941]\n",
      "   [ 0.59882353  0.59882353  0.68666667]\n",
      "   [ 0.61137255  0.61137255  0.69607843]\n",
      "   ..., \n",
      "   [ 0.66784314  0.66470588  0.76196078]\n",
      "   [ 0.66156863  0.65529412  0.75254902]\n",
      "   [ 0.64901961  0.64588235  0.74313725]]]\n",
      "\n",
      "\n",
      " [[[ 0.64901961  0.7054902   0.81843137]\n",
      "   [ 0.63960784  0.70235294  0.84039216]\n",
      "   [ 0.63647059  0.7054902   0.85294118]\n",
      "   ..., \n",
      "   [ 0.7054902   0.74627451  0.84666667]\n",
      "   [ 0.71490196  0.74627451  0.82470588]\n",
      "   [ 0.70862745  0.73686275  0.81215686]]\n",
      "\n",
      "  [[ 0.62392157  0.68666667  0.80901961]\n",
      "   [ 0.6145098   0.68666667  0.82156863]\n",
      "   [ 0.6145098   0.68980392  0.82784314]\n",
      "   ..., \n",
      "   [ 0.66156863  0.7054902   0.80588235]\n",
      "   [ 0.65843137  0.69921569  0.78078431]\n",
      "   [ 0.65215686  0.68666667  0.76509804]]\n",
      "\n",
      "  [[ 0.62392157  0.6772549   0.79333333]\n",
      "   [ 0.62392157  0.68352941  0.79647059]\n",
      "   [ 0.63647059  0.68352941  0.78078431]\n",
      "   ..., \n",
      "   [ 0.65215686  0.69921569  0.8027451 ]\n",
      "   [ 0.64588235  0.69294118  0.78078431]\n",
      "   [ 0.63647059  0.6772549   0.76196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.36666667  0.36352941  0.41686275]\n",
      "   [ 0.36666667  0.3572549   0.39176471]\n",
      "   [ 0.38862745  0.36352941  0.3572549 ]\n",
      "   ..., \n",
      "   [ 0.47960784  0.4545098   0.47647059]\n",
      "   [ 0.43568627  0.42313725  0.47333333]\n",
      "   [ 0.46705882  0.45137255  0.50470588]]\n",
      "\n",
      "  [[ 0.36666667  0.37294118  0.42      ]\n",
      "   [ 0.36352941  0.35411765  0.37921569]\n",
      "   [ 0.37294118  0.34784314  0.34470588]\n",
      "   ..., \n",
      "   [ 0.34156863  0.32588235  0.36352941]\n",
      "   [ 0.44509804  0.42313725  0.47647059]\n",
      "   [ 0.45764706  0.43568627  0.48901961]]\n",
      "\n",
      "  [[ 0.3572549   0.36352941  0.40117647]\n",
      "   [ 0.33529412  0.33215686  0.3572549 ]\n",
      "   [ 0.27882353  0.25686275  0.27254902]\n",
      "   ..., \n",
      "   [ 0.34156863  0.31333333  0.34470588]\n",
      "   [ 0.3854902   0.34470588  0.38235294]\n",
      "   [ 0.3854902   0.34470588  0.38235294]]]]\n",
      "[[[[ 0.53921569  0.49215686  0.46078431]\n",
      "   [ 0.55803922  0.50784314  0.4827451 ]\n",
      "   [ 0.54862745  0.49843137  0.4827451 ]\n",
      "   ..., \n",
      "   [ 0.63333333  0.55490196  0.51098039]\n",
      "   [ 0.65215686  0.57058824  0.52039216]\n",
      "   [ 0.63333333  0.56117647  0.5172549 ]]\n",
      "\n",
      "  [[ 0.47960784  0.43882353  0.50470588]\n",
      "   [ 0.50784314  0.47019608  0.53607843]\n",
      "   [ 0.52039216  0.47960784  0.54862745]\n",
      "   ..., \n",
      "   [ 0.61137255  0.54235294  0.59254902]\n",
      "   [ 0.63333333  0.55803922  0.60509804]\n",
      "   [ 0.63333333  0.56431373  0.60509804]]\n",
      "\n",
      "  [[ 0.57686275  0.53607843  0.64588235]\n",
      "   [ 0.59254902  0.55490196  0.66156863]\n",
      "   [ 0.58627451  0.54862745  0.64901961]\n",
      "   ..., \n",
      "   [ 0.65529412  0.58313725  0.7054902 ]\n",
      "   [ 0.66784314  0.58941176  0.70862745]\n",
      "   [ 0.67411765  0.60196078  0.70862745]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49215686  0.44509804  0.42      ]\n",
      "   [ 0.50470588  0.45137255  0.42313725]\n",
      "   [ 0.33843137  0.31019608  0.24745098]\n",
      "   ..., \n",
      "   [ 0.62705882  0.52980392  0.47647059]\n",
      "   [ 0.59568627  0.49529412  0.42313725]\n",
      "   [ 0.55803922  0.46392157  0.37294118]]\n",
      "\n",
      "  [[ 0.36666667  0.34156863  0.31960784]\n",
      "   [ 0.39490196  0.35411765  0.3227451 ]\n",
      "   [ 0.33215686  0.30392157  0.24117647]\n",
      "   ..., \n",
      "   [ 0.60823529  0.51411765  0.43254902]\n",
      "   [ 0.62078431  0.52039216  0.41372549]\n",
      "   [ 0.59568627  0.50156863  0.38862745]]\n",
      "\n",
      "  [[ 0.49215686  0.45137255  0.44823529]\n",
      "   [ 0.50784314  0.4545098   0.44823529]\n",
      "   [ 0.42941176  0.3854902   0.33529412]\n",
      "   ..., \n",
      "   [ 0.51411765  0.43254902  0.34470588]\n",
      "   [ 0.50784314  0.41686275  0.30078431]\n",
      "   [ 0.5454902   0.46078431  0.34470588]]]\n",
      "\n",
      "\n",
      " [[[ 0.41372549  0.44196078  0.36352941]\n",
      "   [ 0.4827451   0.49529412  0.44196078]\n",
      "   [ 0.37294118  0.37294118  0.33843137]\n",
      "   ..., \n",
      "   [ 0.33529412  0.34470588  0.31647059]\n",
      "   [ 0.31960784  0.32901961  0.30078431]\n",
      "   [ 0.31960784  0.32901961  0.30078431]]\n",
      "\n",
      "  [[ 0.36980392  0.41058824  0.3227451 ]\n",
      "   [ 0.33843137  0.36352941  0.30705882]\n",
      "   [ 0.28823529  0.30078431  0.26941176]\n",
      "   ..., \n",
      "   [ 0.34470588  0.35411765  0.32588235]\n",
      "   [ 0.33843137  0.34784314  0.31960784]\n",
      "   [ 0.3572549   0.36666667  0.33843137]]\n",
      "\n",
      "  [[ 0.36352941  0.41372549  0.32901961]\n",
      "   [ 0.36039216  0.39803922  0.33529412]\n",
      "   [ 0.34156863  0.36980392  0.32588235]\n",
      "   ..., \n",
      "   [ 0.33215686  0.34156863  0.31333333]\n",
      "   [ 0.32901961  0.33843137  0.31019608]\n",
      "   [ 0.36039216  0.36980392  0.34156863]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.30078431  0.34156863  0.34784314]\n",
      "   [ 0.4827451   0.5172549   0.55176471]\n",
      "   [ 0.52039216  0.55490196  0.58941176]\n",
      "   ..., \n",
      "   [ 0.42941176  0.48588235  0.47647059]\n",
      "   [ 0.36352941  0.42313725  0.3854902 ]\n",
      "   [ 0.28823529  0.37607843  0.29764706]]\n",
      "\n",
      "  [[ 0.23803922  0.26        0.27568627]\n",
      "   [ 0.34470588  0.36352941  0.39490196]\n",
      "   [ 0.40117647  0.41686275  0.44509804]\n",
      "   ..., \n",
      "   [ 0.56117647  0.61764706  0.65843137]\n",
      "   [ 0.49529412  0.54862745  0.56745098]\n",
      "   [ 0.39490196  0.46705882  0.4545098 ]]\n",
      "\n",
      "  [[ 0.21294118  0.20980392  0.22235294]\n",
      "   [ 0.28509804  0.28196078  0.30705882]\n",
      "   [ 0.3572549   0.35411765  0.36666667]\n",
      "   ..., \n",
      "   [ 0.52039216  0.58        0.60196078]\n",
      "   [ 0.53294118  0.57686275  0.59568627]\n",
      "   [ 0.50784314  0.56431373  0.57058824]]]\n",
      "\n",
      "\n",
      " [[[ 0.15960784  0.20039216  0.14705882]\n",
      "   [ 0.16588235  0.21921569  0.16588235]\n",
      "   [ 0.18470588  0.25372549  0.20039216]\n",
      "   ..., \n",
      "   [ 0.33529412  0.48901961  0.51098039]\n",
      "   [ 0.33843137  0.48901961  0.50784314]\n",
      "   [ 0.3227451   0.47019608  0.48901961]]\n",
      "\n",
      "  [[ 0.17215686  0.1972549   0.14392157]\n",
      "   [ 0.16588235  0.19411765  0.13764706]\n",
      "   [ 0.17215686  0.20980392  0.14392157]\n",
      "   ..., \n",
      "   [ 0.32588235  0.47019608  0.49529412]\n",
      "   [ 0.33529412  0.47333333  0.48901961]\n",
      "   [ 0.31333333  0.44823529  0.45764706]]\n",
      "\n",
      "  [[ 0.17529412  0.21607843  0.15333333]\n",
      "   [ 0.16901961  0.20980392  0.15019608]\n",
      "   [ 0.17529412  0.21294118  0.15647059]\n",
      "   ..., \n",
      "   [ 0.30078431  0.44196078  0.45137255]\n",
      "   [ 0.31019608  0.44196078  0.44823529]\n",
      "   [ 0.30078431  0.42941176  0.42941176]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.2945098   0.24431373  0.17215686]\n",
      "   [ 0.28823529  0.24431373  0.18470588]\n",
      "   [ 0.27254902  0.25058824  0.18784314]\n",
      "   ..., \n",
      "   [ 0.14078431  0.11882353  0.11254902]\n",
      "   [ 0.13764706  0.14392157  0.12509804]\n",
      "   [ 0.17843137  0.2254902   0.19411765]]\n",
      "\n",
      "  [[ 0.29764706  0.26627451  0.19411765]\n",
      "   [ 0.25372549  0.24117647  0.16901961]\n",
      "   [ 0.24117647  0.24431373  0.17215686]\n",
      "   ..., \n",
      "   [ 0.19098039  0.20980392  0.1972549 ]\n",
      "   [ 0.19411765  0.23176471  0.21607843]\n",
      "   [ 0.18470588  0.25686275  0.23490196]]\n",
      "\n",
      "  [[ 0.31647059  0.26313725  0.19098039]\n",
      "   [ 0.25372549  0.21921569  0.1627451 ]\n",
      "   [ 0.26941176  0.24431373  0.18470588]\n",
      "   ..., \n",
      "   [ 0.30705882  0.37607843  0.36666667]\n",
      "   [ 0.2254902   0.31333333  0.30078431]\n",
      "   [ 0.19098039  0.2945098   0.28196078]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.20980392  0.65843137  0.8372549 ]\n",
      "   [ 0.2254902   0.65215686  0.84980392]\n",
      "   [ 0.23176471  0.65215686  0.85607843]\n",
      "   ..., \n",
      "   [ 0.41058824  0.65529412  0.78705882]\n",
      "   [ 0.34784314  0.56117647  0.71803922]\n",
      "   [ 0.37921569  0.56431373  0.69294118]]\n",
      "\n",
      "  [[ 0.27882353  0.67098039  0.83411765]\n",
      "   [ 0.23803922  0.6772549   0.88431373]\n",
      "   [ 0.25686275  0.67411765  0.85294118]\n",
      "   ..., \n",
      "   [ 0.58941176  0.67098039  0.72745098]\n",
      "   [ 0.54235294  0.65529412  0.74627451]\n",
      "   [ 0.46392157  0.56745098  0.64901961]]\n",
      "\n",
      "  [[ 0.40745098  0.71803922  0.84352941]\n",
      "   [ 0.30078431  0.69294118  0.89058824]\n",
      "   [ 0.31647059  0.70235294  0.86862745]\n",
      "   ..., \n",
      "   [ 0.68980392  0.71176471  0.74627451]\n",
      "   [ 0.47333333  0.52352941  0.56117647]\n",
      "   [ 0.29137255  0.34784314  0.38235294]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.32901961  0.34784314  0.34156863]\n",
      "   [ 0.26627451  0.29764706  0.31333333]\n",
      "   [ 0.26941176  0.31333333  0.35098039]\n",
      "   ..., \n",
      "   [ 0.15333333  0.2254902   0.30078431]\n",
      "   [ 0.16588235  0.21294118  0.26      ]\n",
      "   [ 0.20352941  0.25058824  0.25372549]]\n",
      "\n",
      "  [[ 0.29137255  0.31333333  0.33529412]\n",
      "   [ 0.27254902  0.31960784  0.36980392]\n",
      "   [ 0.27882353  0.34784314  0.42313725]\n",
      "   ..., \n",
      "   [ 0.17529412  0.25058824  0.32588235]\n",
      "   [ 0.15333333  0.20980392  0.26627451]\n",
      "   [ 0.12196078  0.17215686  0.20039216]]\n",
      "\n",
      "  [[ 0.23803922  0.27568627  0.32901961]\n",
      "   [ 0.24431373  0.30705882  0.37607843]\n",
      "   [ 0.25372549  0.34156863  0.42941176]\n",
      "   ..., \n",
      "   [ 0.18470588  0.26313725  0.34156863]\n",
      "   [ 0.16588235  0.23490196  0.30705882]\n",
      "   [ 0.13764706  0.1972549   0.25686275]]]\n",
      "\n",
      "\n",
      " [[[ 0.69294118  0.76196078  0.85294118]\n",
      "   [ 0.68352941  0.75254902  0.84039216]\n",
      "   [ 0.68039216  0.74941176  0.8372549 ]\n",
      "   ..., \n",
      "   [ 0.64901961  0.71176471  0.8027451 ]\n",
      "   [ 0.63960784  0.70862745  0.79647059]\n",
      "   [ 0.63019608  0.70862745  0.79019608]]\n",
      "\n",
      "  [[ 0.70862745  0.75882353  0.84980392]\n",
      "   [ 0.69921569  0.74941176  0.84039216]\n",
      "   [ 0.69607843  0.74627451  0.8372549 ]\n",
      "   ..., \n",
      "   [ 0.6427451   0.70235294  0.79019608]\n",
      "   [ 0.63647059  0.69921569  0.78392157]\n",
      "   [ 0.62392157  0.69607843  0.77764706]]\n",
      "\n",
      "  [[ 0.75254902  0.78705882  0.8654902 ]\n",
      "   [ 0.74313725  0.77764706  0.85294118]\n",
      "   [ 0.74        0.7745098   0.84980392]\n",
      "   ..., \n",
      "   [ 0.64901961  0.69921569  0.78078431]\n",
      "   [ 0.63960784  0.69607843  0.77764706]\n",
      "   [ 0.63019608  0.69921569  0.7745098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.74941176  0.72431373  0.66784314]\n",
      "   [ 0.73686275  0.71176471  0.64901961]\n",
      "   [ 0.73686275  0.71490196  0.6427451 ]\n",
      "   ..., \n",
      "   [ 0.52352941  0.51411765  0.49843137]\n",
      "   [ 0.60823529  0.59568627  0.57058824]\n",
      "   [ 0.62705882  0.61137255  0.57372549]]\n",
      "\n",
      "  [[ 0.72117647  0.69607843  0.63333333]\n",
      "   [ 0.69294118  0.66784314  0.59882353]\n",
      "   [ 0.66470588  0.63960784  0.56117647]\n",
      "   ..., \n",
      "   [ 0.65843137  0.63647059  0.60196078]\n",
      "   [ 0.64901961  0.63019608  0.58941176]\n",
      "   [ 0.64901961  0.63019608  0.58313725]]\n",
      "\n",
      "  [[ 0.72117647  0.69294118  0.6427451 ]\n",
      "   [ 0.69294118  0.66784314  0.60823529]\n",
      "   [ 0.65843137  0.63333333  0.56745098]\n",
      "   ..., \n",
      "   [ 0.71176471  0.6772549   0.63019608]\n",
      "   [ 0.71490196  0.69294118  0.63647059]\n",
      "   [ 0.71176471  0.69607843  0.63647059]]]\n",
      "\n",
      "\n",
      " [[[ 0.81843137  0.81843137  0.84980392]\n",
      "   [ 0.84039216  0.84352941  0.87490196]\n",
      "   [ 0.83411765  0.84039216  0.87490196]\n",
      "   ..., \n",
      "   [ 0.78078431  0.78705882  0.83098039]\n",
      "   [ 0.79333333  0.79960784  0.83411765]\n",
      "   [ 0.79647059  0.79960784  0.83098039]]\n",
      "\n",
      "  [[ 0.79647059  0.79333333  0.81843137]\n",
      "   [ 0.84980392  0.84980392  0.88117647]\n",
      "   [ 0.83098039  0.83411765  0.87176471]\n",
      "   ..., \n",
      "   [ 0.79960784  0.79960784  0.84039216]\n",
      "   [ 0.81215686  0.81529412  0.84666667]\n",
      "   [ 0.75882353  0.76196078  0.79019608]]\n",
      "\n",
      "  [[ 0.76823529  0.74627451  0.76196078]\n",
      "   [ 0.83411765  0.82784314  0.84980392]\n",
      "   [ 0.82470588  0.83098039  0.8654902 ]\n",
      "   ..., \n",
      "   [ 0.79019608  0.79019608  0.82784314]\n",
      "   [ 0.79019608  0.78705882  0.82784314]\n",
      "   [ 0.73372549  0.73686275  0.7745098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.57058824  0.54862745  0.52352941]\n",
      "   [ 0.53921569  0.52352941  0.49843137]\n",
      "   [ 0.51411765  0.49843137  0.47647059]\n",
      "   ..., \n",
      "   [ 0.8027451   0.79647059  0.78392157]\n",
      "   [ 0.82156863  0.81529412  0.80588235]\n",
      "   [ 0.85607843  0.85607843  0.84666667]]\n",
      "\n",
      "  [[ 0.52980392  0.51411765  0.49529412]\n",
      "   [ 0.50784314  0.49843137  0.47647059]\n",
      "   [ 0.49215686  0.47960784  0.46078431]\n",
      "   ..., \n",
      "   [ 0.66784314  0.66470588  0.65843137]\n",
      "   [ 0.73372549  0.73058824  0.72117647]\n",
      "   [ 0.76509804  0.76196078  0.74941176]]\n",
      "\n",
      "  [[ 0.4827451   0.47333333  0.45764706]\n",
      "   [ 0.47019608  0.46392157  0.44509804]\n",
      "   [ 0.47647059  0.46392157  0.44823529]\n",
      "   ..., \n",
      "   [ 0.66156863  0.65529412  0.6427451 ]\n",
      "   [ 0.6145098   0.6145098   0.60823529]\n",
      "   [ 0.61137255  0.61137255  0.60509804]]]]\n",
      "[[[[ 0.59568627  0.45137255  0.25372549]\n",
      "   [ 0.59882353  0.44823529  0.24745098]\n",
      "   [ 0.61764706  0.46392157  0.26      ]\n",
      "   ..., \n",
      "   [ 0.52980392  0.39803922  0.21294118]\n",
      "   [ 0.49529412  0.3854902   0.21294118]\n",
      "   [ 0.46392157  0.36666667  0.20352941]]\n",
      "\n",
      "  [[ 0.57686275  0.45137255  0.26      ]\n",
      "   [ 0.57372549  0.44509804  0.2254902 ]\n",
      "   [ 0.59882353  0.45764706  0.24117647]\n",
      "   ..., \n",
      "   [ 0.52666667  0.39803922  0.1972549 ]\n",
      "   [ 0.49215686  0.3854902   0.20039216]\n",
      "   [ 0.47333333  0.37607843  0.20666667]]\n",
      "\n",
      "  [[ 0.57372549  0.44509804  0.24745098]\n",
      "   [ 0.57372549  0.44196078  0.20352941]\n",
      "   [ 0.59568627  0.44823529  0.21294118]\n",
      "   ..., \n",
      "   [ 0.53607843  0.40745098  0.20666667]\n",
      "   [ 0.50784314  0.39803922  0.20666667]\n",
      "   [ 0.47647059  0.37921569  0.20352941]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.31333333  0.48901961  0.65529412]\n",
      "   [ 0.23176471  0.41372549  0.56431373]\n",
      "   [ 0.1972549   0.37607843  0.52980392]\n",
      "   ..., \n",
      "   [ 0.21921569  0.40431373  0.55803922]\n",
      "   [ 0.14078431  0.30078431  0.43882353]\n",
      "   [ 0.2254902   0.36666667  0.49843137]]\n",
      "\n",
      "  [[ 0.29137255  0.46392157  0.62705882]\n",
      "   [ 0.25372549  0.42        0.56431373]\n",
      "   [ 0.20980392  0.36666667  0.51411765]\n",
      "   ..., \n",
      "   [ 0.18156863  0.3572549   0.50784314]\n",
      "   [ 0.19098039  0.3572549   0.49529412]\n",
      "   [ 0.1627451   0.30078431  0.43568627]]\n",
      "\n",
      "  [[ 0.26941176  0.43568627  0.60196078]\n",
      "   [ 0.27568627  0.42941176  0.56745098]\n",
      "   [ 0.24117647  0.37921569  0.51411765]\n",
      "   ..., \n",
      "   [ 0.17529412  0.34156863  0.48901961]\n",
      "   [ 0.20666667  0.36352941  0.50470588]\n",
      "   [ 0.16588235  0.31019608  0.44509804]]]\n",
      "\n",
      "\n",
      " [[[ 0.8372549   0.8372549   0.8372549 ]\n",
      "   [ 0.82470588  0.82470588  0.82470588]\n",
      "   [ 0.82784314  0.82784314  0.82784314]\n",
      "   ..., \n",
      "   [ 0.83098039  0.83098039  0.83098039]\n",
      "   [ 0.83098039  0.83098039  0.83098039]\n",
      "   [ 0.82784314  0.82784314  0.82784314]]\n",
      "\n",
      "  [[ 0.84666667  0.84666667  0.84666667]\n",
      "   [ 0.8372549   0.8372549   0.8372549 ]\n",
      "   [ 0.8372549   0.8372549   0.8372549 ]\n",
      "   ..., \n",
      "   [ 0.84039216  0.84039216  0.84039216]\n",
      "   [ 0.84039216  0.84039216  0.84039216]\n",
      "   [ 0.8372549   0.8372549   0.8372549 ]]\n",
      "\n",
      "  [[ 0.84352941  0.84352941  0.84352941]\n",
      "   [ 0.83411765  0.83411765  0.83411765]\n",
      "   [ 0.83411765  0.83411765  0.83411765]\n",
      "   ..., \n",
      "   [ 0.8372549   0.8372549   0.8372549 ]\n",
      "   [ 0.8372549   0.8372549   0.8372549 ]\n",
      "   [ 0.83411765  0.83411765  0.83411765]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.37294118  0.41058824  0.37921569]\n",
      "   [ 0.23490196  0.26        0.21607843]\n",
      "   [ 0.15960784  0.17215686  0.1345098 ]\n",
      "   ..., \n",
      "   [ 0.63019608  0.6772549   0.66156863]\n",
      "   [ 0.67098039  0.71803922  0.7054902 ]\n",
      "   [ 0.68980392  0.73372549  0.73058824]]\n",
      "\n",
      "  [[ 0.3572549   0.40117647  0.3572549 ]\n",
      "   [ 0.24431373  0.27882353  0.21294118]\n",
      "   [ 0.21294118  0.23803922  0.16901961]\n",
      "   ..., \n",
      "   [ 0.64588235  0.69294118  0.67411765]\n",
      "   [ 0.68039216  0.72745098  0.71490196]\n",
      "   [ 0.68666667  0.73372549  0.72745098]]\n",
      "\n",
      "  [[ 0.36666667  0.41686275  0.36039216]\n",
      "   [ 0.2945098   0.33529412  0.25058824]\n",
      "   [ 0.28196078  0.31019608  0.21921569]\n",
      "   ..., \n",
      "   [ 0.62705882  0.67411765  0.65843137]\n",
      "   [ 0.66470588  0.71176471  0.69921569]\n",
      "   [ 0.68352941  0.72745098  0.72431373]]]\n",
      "\n",
      "\n",
      " [[[ 0.59568627  0.69607843  0.79647059]\n",
      "   [ 0.59568627  0.68666667  0.78392157]\n",
      "   [ 0.53607843  0.62078431  0.70862745]\n",
      "   ..., \n",
      "   [ 0.81529412  0.82470588  0.83411765]\n",
      "   [ 0.84352941  0.84980392  0.86235294]\n",
      "   [ 0.84666667  0.85607843  0.87176471]]\n",
      "\n",
      "  [[ 0.63333333  0.72745098  0.81843137]\n",
      "   [ 0.63960784  0.72431373  0.80901961]\n",
      "   [ 0.57372549  0.65215686  0.73058824]\n",
      "   ..., \n",
      "   [ 0.82784314  0.82784314  0.84039216]\n",
      "   [ 0.87176471  0.87176471  0.88431373]\n",
      "   [ 0.87176471  0.87490196  0.88745098]]\n",
      "\n",
      "  [[ 0.64588235  0.73058824  0.80588235]\n",
      "   [ 0.65215686  0.72745098  0.79647059]\n",
      "   [ 0.59254902  0.66156863  0.72431373]\n",
      "   ..., \n",
      "   [ 0.82156863  0.81843137  0.82784314]\n",
      "   [ 0.88431373  0.88117647  0.88745098]\n",
      "   [ 0.86862745  0.8654902   0.87490196]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.1972549   0.2254902   0.24117647]\n",
      "   [ 0.19411765  0.22235294  0.23803922]\n",
      "   [ 0.18156863  0.20980392  0.2254902 ]\n",
      "   ..., \n",
      "   [ 0.21607843  0.2254902   0.24431373]\n",
      "   [ 0.12823529  0.14078431  0.14392157]\n",
      "   [ 0.11254902  0.12196078  0.11568627]]\n",
      "\n",
      "  [[ 0.17215686  0.20666667  0.22235294]\n",
      "   [ 0.18470588  0.21921569  0.23490196]\n",
      "   [ 0.17843137  0.21294118  0.22862745]\n",
      "   ..., \n",
      "   [ 0.15960784  0.1627451   0.17529412]\n",
      "   [ 0.11254902  0.11882353  0.10941176]\n",
      "   [ 0.11568627  0.12196078  0.10941176]]\n",
      "\n",
      "  [[ 0.18784314  0.22862745  0.24745098]\n",
      "   [ 0.19411765  0.23490196  0.25686275]\n",
      "   [ 0.20039216  0.24117647  0.26313725]\n",
      "   ..., \n",
      "   [ 0.11568627  0.11882353  0.12509804]\n",
      "   [ 0.11254902  0.11568627  0.10941176]\n",
      "   [ 0.12196078  0.12509804  0.12196078]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.1627451   0.14705882  0.13764706]\n",
      "   [ 0.15960784  0.14392157  0.1345098 ]\n",
      "   [ 0.14705882  0.14392157  0.1345098 ]\n",
      "   ..., \n",
      "   [ 0.13137255  0.12823529  0.12196078]\n",
      "   [ 0.13764706  0.1345098   0.12823529]\n",
      "   [ 0.14078431  0.13764706  0.13137255]]\n",
      "\n",
      "  [[ 0.16588235  0.15019608  0.14078431]\n",
      "   [ 0.1627451   0.15019608  0.14078431]\n",
      "   [ 0.15647059  0.15333333  0.13764706]\n",
      "   ..., \n",
      "   [ 0.13137255  0.12823529  0.12196078]\n",
      "   [ 0.13137255  0.12823529  0.12196078]\n",
      "   [ 0.13764706  0.1345098   0.12823529]]\n",
      "\n",
      "  [[ 0.16588235  0.15019608  0.14078431]\n",
      "   [ 0.16588235  0.15333333  0.13764706]\n",
      "   [ 0.1627451   0.15647059  0.1345098 ]\n",
      "   ..., \n",
      "   [ 0.13764706  0.1345098   0.12823529]\n",
      "   [ 0.13764706  0.1345098   0.12823529]\n",
      "   [ 0.14078431  0.13764706  0.13137255]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.20352941  0.17843137  0.14078431]\n",
      "   [ 0.20666667  0.18156863  0.14705882]\n",
      "   [ 0.20666667  0.18156863  0.14705882]\n",
      "   ..., \n",
      "   [ 0.18784314  0.17843137  0.26313725]\n",
      "   [ 0.19098039  0.17843137  0.28196078]\n",
      "   [ 0.17215686  0.1627451   0.23176471]]\n",
      "\n",
      "  [[ 0.20352941  0.17843137  0.14392157]\n",
      "   [ 0.20666667  0.18156863  0.14705882]\n",
      "   [ 0.20666667  0.18156863  0.14705882]\n",
      "   ..., \n",
      "   [ 0.18470588  0.17529412  0.26313725]\n",
      "   [ 0.18470588  0.17529412  0.27568627]\n",
      "   [ 0.17843137  0.16901961  0.24745098]]\n",
      "\n",
      "  [[ 0.1972549   0.17215686  0.13764706]\n",
      "   [ 0.20039216  0.17529412  0.14078431]\n",
      "   [ 0.20352941  0.17843137  0.14392157]\n",
      "   ..., \n",
      "   [ 0.17529412  0.17215686  0.25686275]\n",
      "   [ 0.18156863  0.17215686  0.26627451]\n",
      "   [ 0.17843137  0.1627451   0.24745098]]]\n",
      "\n",
      "\n",
      " [[[ 0.17843137  0.2254902   0.13764706]\n",
      "   [ 0.14705882  0.21294118  0.10941176]\n",
      "   [ 0.17215686  0.22862745  0.15647059]\n",
      "   ..., \n",
      "   [ 0.29137255  0.3572549   0.34470588]\n",
      "   [ 0.38862745  0.4545098   0.45137255]\n",
      "   [ 0.33529412  0.37921569  0.38862745]]\n",
      "\n",
      "  [[ 0.13764706  0.17843137  0.11882353]\n",
      "   [ 0.1627451   0.21607843  0.12196078]\n",
      "   [ 0.17529412  0.21294118  0.14705882]\n",
      "   ..., \n",
      "   [ 0.46078431  0.52039216  0.53294118]\n",
      "   [ 0.56745098  0.62705882  0.65529412]\n",
      "   [ 0.42627451  0.46705882  0.51098039]]\n",
      "\n",
      "  [[ 0.13764706  0.17843137  0.1345098 ]\n",
      "   [ 0.14705882  0.19098039  0.11882353]\n",
      "   [ 0.20666667  0.2254902   0.17529412]\n",
      "   ..., \n",
      "   [ 0.58313725  0.63960784  0.67098039]\n",
      "   [ 0.59254902  0.64901961  0.70235294]\n",
      "   [ 0.46392157  0.50470588  0.57372549]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.41372549  0.50470588  0.35411765]\n",
      "   [ 0.42313725  0.51411765  0.36352941]\n",
      "   [ 0.42627451  0.52039216  0.36980392]\n",
      "   ..., \n",
      "   [ 0.40431373  0.50156863  0.36352941]\n",
      "   [ 0.40745098  0.49529412  0.36352941]\n",
      "   [ 0.3854902   0.47960784  0.34784314]]\n",
      "\n",
      "  [[ 0.42313725  0.51411765  0.36039216]\n",
      "   [ 0.42627451  0.51098039  0.36039216]\n",
      "   [ 0.43568627  0.52352941  0.37294118]\n",
      "   ..., \n",
      "   [ 0.41686275  0.51411765  0.37294118]\n",
      "   [ 0.41058824  0.49843137  0.36352941]\n",
      "   [ 0.38862745  0.47960784  0.34784314]]\n",
      "\n",
      "  [[ 0.39803922  0.49529412  0.34470588]\n",
      "   [ 0.39803922  0.48588235  0.33843137]\n",
      "   [ 0.41686275  0.50156863  0.35411765]\n",
      "   ..., \n",
      "   [ 0.39176471  0.48901961  0.35098039]\n",
      "   [ 0.39803922  0.48588235  0.35411765]\n",
      "   [ 0.38862745  0.47647059  0.35098039]]]\n",
      "\n",
      "\n",
      " [[[ 0.32901961  0.34470588  0.33529412]\n",
      "   [ 0.40745098  0.42313725  0.4545098 ]\n",
      "   [ 0.41058824  0.43254902  0.45764706]\n",
      "   ..., \n",
      "   [ 0.52352941  0.57058824  0.57686275]\n",
      "   [ 0.52352941  0.56745098  0.58313725]\n",
      "   [ 0.73686275  0.7745098   0.79960784]]\n",
      "\n",
      "  [[ 0.31647059  0.32901961  0.31960784]\n",
      "   [ 0.36352941  0.37921569  0.40431373]\n",
      "   [ 0.31333333  0.33529412  0.35411765]\n",
      "   ..., \n",
      "   [ 0.36666667  0.39803922  0.37921569]\n",
      "   [ 0.3227451   0.3572549   0.35098039]\n",
      "   [ 0.47647059  0.5172549   0.52352941]]\n",
      "\n",
      "  [[ 0.31647059  0.32901961  0.31960784]\n",
      "   [ 0.38235294  0.39803922  0.41372549]\n",
      "   [ 0.2945098   0.3227451   0.33215686]\n",
      "   ..., \n",
      "   [ 0.33215686  0.35411765  0.31960784]\n",
      "   [ 0.26627451  0.2945098   0.26941176]\n",
      "   [ 0.2945098   0.33215686  0.31647059]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.48588235  0.50156863  0.40117647]\n",
      "   [ 0.51411765  0.51411765  0.42      ]\n",
      "   [ 0.50470588  0.50156863  0.41372549]\n",
      "   ..., \n",
      "   [ 0.43882353  0.43568627  0.37607843]\n",
      "   [ 0.2945098   0.28823529  0.27254902]\n",
      "   [ 0.18470588  0.18470588  0.18784314]]\n",
      "\n",
      "  [[ 0.46078431  0.47960784  0.3854902 ]\n",
      "   [ 0.48588235  0.48901961  0.39803922]\n",
      "   [ 0.50470588  0.49529412  0.41058824]\n",
      "   ..., \n",
      "   [ 0.46078431  0.46392157  0.39490196]\n",
      "   [ 0.30705882  0.30392157  0.28509804]\n",
      "   [ 0.18470588  0.18470588  0.18470588]]\n",
      "\n",
      "  [[ 0.46392157  0.47647059  0.38235294]\n",
      "   [ 0.47960784  0.4827451   0.39490196]\n",
      "   [ 0.50470588  0.50156863  0.41686275]\n",
      "   ..., \n",
      "   [ 0.46392157  0.46078431  0.39490196]\n",
      "   [ 0.31333333  0.30392157  0.28196078]\n",
      "   [ 0.18470588  0.18156863  0.18156863]]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, *image_shape], name=\"x\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name=\"y\")\n",
    "    \n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Tensor(\"Variable/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"Variable_1/read:0\", shape=(2, 2, 5, 10), dtype=float32)\n",
      "[1, 4, 4, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size (2, 2)\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add:0\", shape=(?, 8, 8, 10), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 8, 8, 10), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 4, 4, 10), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(x_tensor, x_tensor.shape[2],  conv_num_outputs,  conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #print(  conv_num_outputs,  conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #10 (2, 2) (4, 4) (2, 2) (2, 2)\n",
    "    #print(conv_ksize)\n",
    "    # Store layers weight & bias\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    print(x_tensor.shape[2])\n",
    "    \n",
    "    FB = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    print(FB)\n",
    "    #Check the standard deviation and mean stuff\n",
    "    FW = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1], x_tensor.get_shape().as_list()[-1], conv_num_outputs],stddev=0.05, mean=0))\n",
    "    print(FW)\n",
    "    \n",
    "    padding = 'SAME'\n",
    "    \n",
    "    new_strides = [1,conv_strides[0],conv_strides[1],1]\n",
    "    print(new_strides)\n",
    "    new_pool_strides = [1,pool_strides[0],pool_strides[1],1]\n",
    "    print(new_pool_strides)\n",
    "    print(\"pool size\",  pool_ksize)\n",
    "    new_pool_ksize = [1,pool_ksize[0],pool_ksize[1],1]\n",
    "    print(new_pool_ksize)\n",
    "\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, FW, new_strides, padding) + FB\n",
    "    \n",
    "    print(conv_layer)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    print(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, new_pool_ksize, new_pool_strides,padding)\n",
    "    print(conv_layer)\n",
    "\n",
    "    \n",
    "    return conv_layer\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "                     \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 10, 30, 6), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1800), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(x_tensor)\n",
    "    new_thing =  tf.contrib.layers.flatten(x_tensor)\n",
    "    print(new_thing)\n",
    "    return new_thing\n",
    "    \n",
    "\n",
    "    #return None\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # ROB - THINK ABOUT THE non-linerarity? it can be changed here - , activation_fn=tf.nn.relu\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=tf.nn.relu)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Tensor(\"Variable/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_1/read:0\", shape=(3, 3, 3, 32), dtype=float32)\n",
      "[1, 2, 2, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Rob here Tensor(\"MaxPool:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "8\n",
      "Tensor(\"Variable_2/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_3/read:0\", shape=(3, 3, 32, 32), dtype=float32)\n",
      "[1, 1, 1, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add_1:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Rob here Tensor(\"MaxPool_1:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "4\n",
      "Tensor(\"Variable_4/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_5/read:0\", shape=(3, 3, 32, 32), dtype=float32)\n",
      "[1, 1, 1, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add_2:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 2048), dtype=float32)\n",
      "32\n",
      "Tensor(\"Variable_6/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_7/read:0\", shape=(3, 3, 3, 32), dtype=float32)\n",
      "[1, 2, 2, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add_3:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Rob here Tensor(\"MaxPool_3:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "8\n",
      "Tensor(\"Variable_8/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_9/read:0\", shape=(3, 3, 32, 32), dtype=float32)\n",
      "[1, 1, 1, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add_4:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_4:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Rob here Tensor(\"MaxPool_4:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "4\n",
      "Tensor(\"Variable_10/read:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"Variable_11/read:0\", shape=(3, 3, 32, 32), dtype=float32)\n",
      "[1, 1, 1, 1]\n",
      "[1, 2, 2, 1]\n",
      "pool size [2, 2]\n",
      "[1, 2, 2, 1]\n",
      "Tensor(\"add_5:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"Relu_5:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_5:0\", shape=(?, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"Flatten_1/Reshape:0\", shape=(?, 2048), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    # conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    #------ from above - print(  conv_num_outputs,  conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #------- results from above - 10 (2, 2) (4, 4) (2, 2) (2, 2)\n",
    "    #-------- tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None)\n",
    "\n",
    "    \n",
    "    #x_tensor = x\n",
    "    conv_num_outputs = 32\n",
    "    conv_ksize = [3,3] # original 2,2\n",
    "    conv_strides = [2,2] # original 4,4\n",
    "    pool_ksize = [2,2] # original 2,2\n",
    "    pool_strides = [2,2] # original 2,2\n",
    "    num_outputs = 10\n",
    "    \n",
    "    first_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print(\"Rob here\", first_layer)\n",
    "    \n",
    "    conv_strides = [1,1] # original 4,4\n",
    "    \n",
    "    second_layer = conv2d_maxpool(first_layer, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #dropout_thing = tf.nn.dropout(first_layer, keep_prob)\n",
    "    print(\"Rob here\", second_layer)\n",
    "    \n",
    "    #pool_ksize = [1,1] # original 2,2\n",
    "    #pool_strides = [1,1] # original 2,2\n",
    "    \n",
    "    third_layer = conv2d_maxpool(second_layer, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #dropout_thing = first_layer\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    flatter = flatten(first_layer)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    first_fully_connected_layer = fully_conn(flatter, 128)\n",
    "    dropout_thing = tf.nn.dropout(first_fully_connected_layer, keep_prob)\n",
    "    second_fully_connected_layer = fully_conn(dropout_thing, 64)\n",
    "    dropout_thing = tf.nn.dropout(second_fully_connected_layer, keep_prob)\n",
    "    third_fully_connected_layer = fully_conn(dropout_thing, 32)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    output_layer = output(dropout_thing, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "    \n",
    "    #tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    " \n",
    "\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "    #pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # Determine if the predictions are correct\n",
    "    \n",
    "    loss = session.run(cost,feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    accuracy_new = session.run(accuracy,  feed_dict={x: valid_features, y: valid_labels,  keep_prob: 1.0})\n",
    "    \n",
    "    print('loss', loss, 'accuracy', accuracy_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "# REMEMBER - you have removed the dropout layer\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss 2.21523 accuracy 0.2116\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss 2.09829 accuracy 0.3218\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss 1.99245 accuracy 0.3888\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss 1.91669 accuracy 0.4094\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss 1.8409 accuracy 0.4262\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss 1.82221 accuracy 0.4498\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss 1.74103 accuracy 0.4438\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss 1.64781 accuracy 0.4708\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss 1.61394 accuracy 0.4664\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss 1.55056 accuracy 0.4852\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss 1.50217 accuracy 0.4904\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss 1.44792 accuracy 0.4902\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss 1.38892 accuracy 0.4916\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss 1.32574 accuracy 0.5006\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss 1.29519 accuracy 0.506\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss 1.28094 accuracy 0.5066\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss 1.21512 accuracy 0.5156\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss 1.22809 accuracy 0.501\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss 1.15426 accuracy 0.5004\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss 1.14246 accuracy 0.5204\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss 2.28524 accuracy 0.192\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss 2.20195 accuracy 0.2382\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss 1.82187 accuracy 0.3154\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss 1.78345 accuracy 0.3572\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss 1.75021 accuracy 0.3934\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss 1.91177 accuracy 0.4084\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss 1.6345 accuracy 0.426\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss 1.42904 accuracy 0.4194\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss 1.64294 accuracy 0.4528\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss 1.54829 accuracy 0.4558\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss 1.78209 accuracy 0.4586\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss 1.54616 accuracy 0.4752\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss 1.22535 accuracy 0.4862\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss 1.47671 accuracy 0.4866\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss 1.47968 accuracy 0.4856\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss 1.6084 accuracy 0.5042\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss 1.40227 accuracy 0.4972\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss 1.17213 accuracy 0.5044\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss 1.39882 accuracy 0.5172\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss 1.44116 accuracy 0.4938\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss 1.57456 accuracy 0.5124\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss 1.35114 accuracy 0.5058\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss 1.07712 accuracy 0.5142\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss 1.38033 accuracy 0.5246\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss 1.3548 accuracy 0.5166\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss 1.52314 accuracy 0.5294\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss 1.3191 accuracy 0.531\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss 1.04411 accuracy 0.5118\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss 1.31872 accuracy 0.5354\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss 1.2834 accuracy 0.5246\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss 1.55738 accuracy 0.5094\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss 1.31316 accuracy 0.5352\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss 1.00771 accuracy 0.5326\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss 1.32288 accuracy 0.5374\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss 1.21044 accuracy 0.528\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss 1.38267 accuracy 0.5416\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss 1.2067 accuracy 0.546\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss 0.985203 accuracy 0.5294\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss 1.34465 accuracy 0.5458\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss 1.24319 accuracy 0.5184\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss 1.34135 accuracy 0.5506\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss 1.15613 accuracy 0.5494\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss 0.972844 accuracy 0.5398\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss 1.28572 accuracy 0.5534\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss 1.15407 accuracy 0.5492\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss 1.29327 accuracy 0.5572\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss 1.1293 accuracy 0.5514\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss 0.937316 accuracy 0.5466\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss 1.30605 accuracy 0.543\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss 1.09312 accuracy 0.5454\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss 1.30406 accuracy 0.5628\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss 1.06247 accuracy 0.5616\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss 0.908339 accuracy 0.5492\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss 1.20433 accuracy 0.5676\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss 1.08329 accuracy 0.5574\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss 1.26399 accuracy 0.5626\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss 1.03491 accuracy 0.5608\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss 0.894045 accuracy 0.5542\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss 1.16224 accuracy 0.567\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss 1.02918 accuracy 0.5618\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss 1.16243 accuracy 0.568\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss 1.02354 accuracy 0.5734\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss 0.886546 accuracy 0.5664\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss 1.17498 accuracy 0.571\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss 1.01663 accuracy 0.5674\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss 1.11205 accuracy 0.5736\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss 0.990425 accuracy 0.5604\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss 0.839702 accuracy 0.5678\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss 1.13877 accuracy 0.5742\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss 0.983262 accuracy 0.5638\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss 1.12275 accuracy 0.5696\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss 0.974172 accuracy 0.5762\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss 0.837119 accuracy 0.5748\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss 1.10857 accuracy 0.581\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss 0.991378 accuracy 0.5718\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss 1.07742 accuracy 0.5728\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss 0.931536 accuracy 0.5726\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss 0.838352 accuracy 0.5738\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss 1.07558 accuracy 0.577\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss 0.973395 accuracy 0.569\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss 1.01981 accuracy 0.58\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss 0.921686 accuracy 0.5736\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss 0.833586 accuracy 0.5776\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss 1.01489 accuracy 0.5814\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss 0.925644 accuracy 0.5844\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss 0.98272 accuracy 0.5842\n",
      "Epoch 18, CIFAR-10 Batch 2:  loss 0.935367 accuracy 0.5834\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss 0.787112 accuracy 0.5918\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss 1.01998 accuracy 0.5854\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss 0.910565 accuracy 0.5892\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss 1.00787 accuracy 0.5764\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss 0.939818 accuracy 0.5816\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss 0.796828 accuracy 0.5794\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss 1.02071 accuracy 0.5782\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss 0.861267 accuracy 0.5834\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss 0.957049 accuracy 0.5816\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss 0.931681 accuracy 0.578\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss 0.752895 accuracy 0.5874\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss 0.962255 accuracy 0.586\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss 0.869846 accuracy 0.58\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5829707278481012\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f634c72a080>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
